{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.1 64-bit"
  },
  "interpreter": {
   "hash": "07a70a5077e9c9feae5d08fa41fc44d95abc22f10394969018e5e0f4ca96aa5b"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\domen\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\ipykernel\\pylab\\config.py:70: DeprecationWarning: InlineBackend._figure_formats_changed is deprecated in traitlets 4.1: use @observe and @unobserve instead.\n",
      "  def _figure_formats_changed(self, name, old, new):\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\domen\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import base64\n",
    "import tweepy as tw\n",
    "import re\n",
    "import numpy as np\n",
    "import string\n",
    "import unicodedata\n",
    "import nltk\n",
    "import gensim\n",
    "import pyLDAvis.gensim_models\n",
    "import pickle \n",
    "import pyLDAvis\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import gensim.corpora as corpora\n",
    "import streamlit as st\n",
    "from pprint import pprint\n",
    "from nltk.util import bigrams\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.utils import simple_preprocess\n",
    "from streamlit_metrics import metric, metric_row\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation as LDA\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "source": [
    "# Step 1: Set up Twitter API access\n",
    "Set up the project here: https://developer.twitter.com/en/portal/projects-and-apps\n",
    "\n",
    "Using this site as reference: https://www.earthdatascience.org/courses/use-data-open-source-python/intro-to-apis/twitter-data-in-python/"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\domen\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\ipykernel\\ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "# English stopwords\n",
    "stopwords_en = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "# French stopwords\n",
    "stopwords_fr = nltk.corpus.stopwords.words('french')\n",
    "\n",
    "# Function 1\n",
    "#-----------------\n",
    "def get_table_download_link(df):\n",
    "    # Reference: https://discuss.streamlit.io/t/how-to-download-file-in-streamlit/1806\n",
    "    \"\"\"\n",
    "    Generates a link allowing the data in a given panda dataframe to be downloaded\n",
    "    in:  dataframe\n",
    "    out: href string\n",
    "    \"\"\"\n",
    "    csv = df.to_csv(index=False)\n",
    "    b64 = base64.b64encode(csv.encode()).decode()  # some strings <-> bytes conversions necessary here\n",
    "    href = f'<a href=\"data:file/csv;base64,{b64}\" download=\"tweets.csv\">Download CSV file</a>'\n",
    "    return href"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\domen\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\ipykernel\\ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "\n",
    "\n",
    "# Function 2: \n",
    "#----------------\n",
    "# Hit twitter api & add basic features & output 2 dataframes\n",
    "# @st.cache(suppress_st_warning=True,allow_output_mutation=True)\n",
    "def twitter_get(select_hashtag_keyword, select_language, user_word_entry, num_of_tweets):  \n",
    "    \n",
    "    # Set up Twitter API access\n",
    "    # Define access keys and tokens\n",
    "    #consumer_key = st.secrets['consumer_key']\n",
    "    #consumer_secret = st.secrets['consumer_secret']\n",
    "    #access_token = st.secrets['access_token']\n",
    "    #access_token_secret = st.secrets['access_token_secret']\n",
    "    \n",
    "    # Reference: https://gist.github.com/radcliff/47af9f6238c95f6ae239\n",
    "    # Load yml file to dictionary :)\n",
    "    credentials = yaml.load(open('./credentials.yml'), Loader=yaml.FullLoader)\n",
    "\n",
    "    # Define access keys and tokens\n",
    "    consumer_key = credentials['dom_twitter_api']['consumer_key']\n",
    "    consumer_secret = credentials['dom_twitter_api']['consumer_secret']\n",
    "    access_token = credentials['dom_twitter_api']['access_token']\n",
    "    access_token_secret = credentials['dom_twitter_api']['access_token_secret']\n",
    "\n",
    "    auth = tw.OAuthHandler(consumer_key, consumer_secret)\n",
    "    auth.set_access_token(access_token, access_token_secret)\n",
    "    api = tw.API(auth, wait_on_rate_limit = True)\n",
    "    \n",
    "    # Keyword or hashtag\n",
    "    if select_hashtag_keyword == 'Hashtag':\n",
    "        user_word = '#' + user_word_entry\n",
    "    else:\n",
    "        user_word = user_word_entry\n",
    "\n",
    "    # Retweets (assumes yes)\n",
    "    user_word = user_word + ' -filter:retweets'\n",
    "    # The following is based on user language selection\n",
    "\n",
    "    # ...English Language\n",
    "    if select_language == 'English':\n",
    "        language = 'en'\n",
    "\n",
    "    # ...French Language\n",
    "    if select_language == 'French':\n",
    "        language = 'fr'\n",
    "\n",
    "    # Retweets (assumes yes)\n",
    "    user_word = user_word + ' -filter:retweets'\n",
    "\n",
    "    # Scenario 1: All languages\n",
    "    if select_language == 'All':\n",
    "        tweets = tw.Cursor(api.search,\n",
    "                            q=user_word,\n",
    "                            tweet_mode = \"extended\").items(num_of_tweets)\n",
    "\n",
    "    # Scenario 2: Specific language (English or French)\n",
    "    if select_language != 'All':\n",
    "        tweets = tw.Cursor(api.search,\n",
    "                            q=user_word,\n",
    "                            tweet_mode = \"extended\",\n",
    "                            lang=language).items(num_of_tweets)\n",
    "\n",
    "    # Store as dataframe\n",
    "    tweet_metadata = [[tweet.created_at, tweet.id, tweet.full_text, tweet.user.screen_name, tweet.retweet_count, tweet.favorite_count] for tweet in tweets]\n",
    "    df_tweets = pd.DataFrame(data=tweet_metadata, columns=['created_at', 'id', 'full_text', 'user', 'rt_count', 'fav_count'])\n",
    "\n",
    "    # Add a new data variable\n",
    "    df_tweets['created_dt'] = df_tweets['created_at'].dt.date\n",
    "\n",
    "    # Add a new time variable\n",
    "    df_tweets['created_time'] = df_tweets['created_at'].dt.time\n",
    "\n",
    "    # Create a new text variable to do manipulations on \n",
    "    df_tweets['clean_text'] = df_tweets.full_text\n",
    "\n",
    "\n",
    "    df_new = df_tweets[[\"created_dt\", \"created_time\", \"full_text\", \"user\", \"rt_count\", \"fav_count\"]]\n",
    "    df_new = df_new.rename(columns = {\"created_dt\": \"Date\", \n",
    "                                 \"created_time\": \"Time\", \n",
    "                                  \"full_text\": \"Tweet\", \n",
    "                                  \"user\": \"Username\", \n",
    "                                  \"rt_count\": \"Retweets\",  \n",
    "                                  \"fav_count\": \"Favourites\"})\n",
    "\n",
    "    return df_tweets, df_new\n",
    "\n",
    "# Function 2: \n",
    "#----------------\n",
    "# takes in pandas dataframe after first twitter scrape\n",
    "# returns a pandas dataframe that has classified each tweet as relating to an nhl team\n",
    "\n",
    "def classify_nhl_team(df):\n",
    "    \n",
    "    # Create a new and smaller dataframe to work with called df\n",
    "    df = df[[\"id\", \"user\", \"created_at\", \"full_text\", \"clean_text\"]]\n",
    "    # Convert tweet to lower\n",
    "    df.clean_text = df.clean_text.str.lower()  \n",
    "    # Classification: If a team's keywords come up, classify as a team specific indicator, with value = team name\n",
    "    df['ANA'] = pd.np.where(df['clean_text'].str.contains('anaheim|ducks|#flytogether'), 'Anaheim Ducks', '0')\n",
    "    df['ARZ'] = pd.np.where(df['clean_text'].str.contains('arizona|coyotes|#yotes'), 'Arizona Coyotes', '0')\n",
    "    df['BOS'] = pd.np.where(df['clean_text'].str.contains('boston|bruins|#nhlbruins'), 'Boston Bruins', '0')\n",
    "    df['BUF'] = pd.np.where(df['clean_text'].str.contains('buffalo|sabres|#letsgobuffalo'), 'Buffalo Sabres', '0')\n",
    "    df['CGY'] = pd.np.where(df['clean_text'].str.contains('calgary|flames|#cofred'), 'Calgary Flames', '0')\n",
    "    df['CAR'] = pd.np.where(df['clean_text'].str.contains('carolina|hurricanes|#canes|#letsgocanes'), 'Carolina Hurricanes', '0')\n",
    "    df['CHI'] = pd.np.where(df['clean_text'].str.contains('chicago|blackhawks|#blackhawks'), 'Chicago Blackhawks', '0')\n",
    "    df['COL'] = pd.np.where(df['clean_text'].str.contains('colorado|avalanche|#GoAvsGo'), 'Colorado Avalanche', '0')\n",
    "    df['CBJ'] = pd.np.where(df['clean_text'].str.contains('columbus|bluejackets|jackets|#CBJ'), 'Columbus Blue Jackets', '0')\n",
    "    df['DAL'] = pd.np.where(df['clean_text'].str.contains('dallas|stars|#gostars'), 'Dallas Stars', '0')\n",
    "    df['DET'] = pd.np.where(df['clean_text'].str.contains('detroit|redwings|#lgrw'), 'Detroit Red Wings', '0')\n",
    "    df['EDM'] = pd.np.where(df['clean_text'].str.contains('edmonton|oilers|#oilers'), 'Edmonton Oilers', '0')\n",
    "    df['FLA'] = pd.np.where(df['clean_text'].str.contains('florida|panthers|#flapanthers'), 'Florida Panthers', '0')\n",
    "    df['LAK'] = pd.np.where(df['clean_text'].str.contains('los angeles|kings|#gokingsgo'), 'Los Angeles Kings', '0')\n",
    "    df['MIN'] = pd.np.where(df['clean_text'].str.contains('minnesota|wild|#mnwild'), 'Minnesota Wild', '0')\n",
    "    df['MTL'] = pd.np.where(df['clean_text'].str.contains('montreal|canadiens|habs|#gohabsgo'), 'Montreal Canadiens', '0')\n",
    "    df['NSH'] = pd.np.where(df['clean_text'].str.contains('nashville|predators|#preds'), 'Nashville Predators', '0')\n",
    "    df['NJD'] = pd.np.where(df['clean_text'].str.contains('new jersey|devils|#njdevils'), 'New Jersey Devils', '0')\n",
    "    df['NYI'] = pd.np.where(df['clean_text'].str.contains('new york islanders|islanders|#isles'), 'New York Islanders', '0')\n",
    "    df['NYR'] = pd.np.where(df['clean_text'].str.contains('new york rangers|rangers|#nyr'), 'New York Rangers', '0')\n",
    "    df['OTT'] = pd.np.where(df['clean_text'].str.contains('ottawa|senators|sens|#gosensgo'), 'Ottawa Senators', '0')\n",
    "    df['PHI'] = pd.np.where(df['clean_text'].str.contains('philadelphia|flyers|#anytimeanywhere'), 'Philadelphia Flyers', '0')\n",
    "    df['PIT'] = pd.np.where(df['clean_text'].str.contains('pittsburgh|penguins|#pens|#letsgopens'), 'Pittsburgh Penguins', '0')\n",
    "    df['SJS'] = pd.np.where(df['clean_text'].str.contains('san jose|sharks|#sjsharks'), 'San Jose Sharks', '0')\n",
    "    df['SEA'] = pd.np.where(df['clean_text'].str.contains('seattle|kraken|#seakraken'), 'Seattle Kraken', '0')\n",
    "    df['STL'] = pd.np.where(df['clean_text'].str.contains('stlouis|st. louis|st louis|blues|#stblues'), 'St Louis Blues', '0')\n",
    "    df['TBL'] = pd.np.where(df['clean_text'].str.contains('tampa bay|lightning|tampa|#gobolts'), 'Tampa Bay Lightning', '0')\n",
    "    df['TOR'] = pd.np.where(df['clean_text'].str.contains('toronto|maple leafs|#leafsforever'), 'Toronto Maple Leafs', '0')\n",
    "    df['VAN'] = pd.np.where(df['clean_text'].str.contains('vancouver|canucks|#canucks'), 'Vancouver Canucks', '0') \n",
    "    df['VGK'] = pd.np.where(df['clean_text'].str.contains('vegas|golden knights|knights|#vegasborn'), 'Vegas Golden Knights', '0')\n",
    "    df['WSH'] = pd.np.where(df['clean_text'].str.contains('washington|capitals|#caps|#allcaps'), 'Washington Capitals', '0')\n",
    "    df['WPG'] = pd.np.where(df['clean_text'].str.contains('winnipeg|jets|#gojetsgo'), 'Winnipeg Jets', '0')\n",
    "\n",
    "    # Define columns to concatenate\n",
    "    cols = ['ANA', 'ARZ', 'BOS', 'BUF', 'CGY', 'CAR', 'CHI', 'COL', 'CBJ', 'DAL', 'DET', 'EDM', 'FLA', 'LAK', 'MIN', 'MTL', 'NSH', 'NJD', 'NYI', 'NYR', 'OTT', 'PHI', 'PIT', 'SJS', 'SEA', 'STL', 'TBL', 'TOR', 'VAN', 'VGK', 'WSH', 'WPG']\n",
    "    # Concatenate columns\n",
    "    df['teams_concat'] = df[cols].apply(lambda x: ','.join(x), axis=1)\n",
    "    # Replace 0s with nothing\n",
    "    df['teams_concat'] = df.teams_concat.str.replace('0,|0|,0','').str.strip()\n",
    "    # ind variable - if multiple commas exist (proxy for num of teams), then 1 else 0\n",
    "    df['multiple_teams'] = np.where(df.teams_concat.str.contains(\",\"), 1, 0)\n",
    "    # ind variable - if the length of teams_concat is equal to 0 (proxy for no teams matched), then 1 else 0\n",
    "    df['no_matches'] = np.where(df.teams_concat.str.len() == 0, 1, 0)\n",
    "\n",
    "    # Stash a dataframe with those tweets that were never paired to a keyword \n",
    "    df_nomatch = df.loc[df['no_matches'] == 1]\n",
    "    # Select columns\n",
    "    df_nomatch = df_nomatch[['id', 'user', 'created_at', 'full_text', 'clean_text', 'multiple_teams', 'no_matches', 'teams_concat']]\n",
    "\n",
    "    # Melt the dataframe such that each row is equal to a tweet that was matched to a team's keyword (introducing dups to tweets)\n",
    "    melted_df = df.melt(\n",
    "                    id_vars = ['id', 'user', 'created_at', 'full_text', 'clean_text', 'multiple_teams', 'no_matches', 'teams_concat'],\n",
    "                    value_vars = ['ANA', 'ARZ', 'BOS', 'BUF', 'CGY', 'CAR', 'CHI', 'COL', 'CBJ', 'DAL', 'DET', 'EDM', 'FLA', 'LAK', 'MIN', 'MTL', 'NSH', 'NJD', 'NYI', 'NYR', 'OTT', 'PHI', 'PIT', 'SJS', 'SEA', 'STL', 'TBL', 'TOR', 'VAN', 'VGK', 'WSH', 'WPG'],\n",
    "                    var_name = 'nhl_team_abbr',\n",
    "                    value_name = \"nhl_team\"\n",
    "                    )\n",
    "    # Filter out 0s \n",
    "    melted_df = melted_df.loc[melted_df['nhl_team'] != '0']\n",
    "\n",
    "    # Add feature parity to df_nomatch\n",
    "    df_nomatch['nhl_team_abbr'] = 'Unknown' \n",
    "    df_nomatch['nhl_team'] = 'Unknown' \n",
    "\n",
    "    # Append df_nomatch to melted_df to get df_clean\n",
    "    df_clean = melted_df.append(df_nomatch)\n",
    "\n",
    "    # Show a few rows of data\n",
    "    df_clean.head(5)\n",
    "    #print('total rows:', len(df_clean),'melted_rows:', (len(melted_df)), 'nomatch_rows:', len(df_nomatch))\n",
    "\n",
    "    # Extend df_clean by joining in data about the team\n",
    "    df_merged = pd.merge(df_clean,\n",
    "                        teams,\n",
    "                        on = 'nhl_team',\n",
    "                        how = 'left',\n",
    "                        indicator = True)\n",
    "\n",
    "    return df_merged\n",
    "\n",
    "#classify_nhl_team(df_tweets).head(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\domen\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\ipykernel\\ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n  and should_run_async(code)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   twitter_handle         nhl_team  conference 2022_division 2021_division  \\\n",
       "0   @AnaheimDucks    Anaheim Ducks  Westernern       Pacific          West   \n",
       "1  @ArizonCoyotes  Arizona Coyotes     Western       Central          West   \n",
       "2      @NHLBruins    Boston Bruins     Eastern      Atlantic          East   \n",
       "\n",
       "   expansion_type  2021_hashtag other_hashtag  \\\n",
       "0  Rest of League  #FlyTogether        #ducks   \n",
       "1  Rest of League        #Yotes      #coyotes   \n",
       "2  Rest of League    #NHLBruins       #bruins   \n",
       "\n",
       "                                               image primary_hex  \\\n",
       "0  http://www.capsinfo.com/images/NHL_Team_Logos/...     #F47A38   \n",
       "1  http://www.capsinfo.com/images/NHL_Team_Logos/...     #8C2633   \n",
       "2  http://www.capsinfo.com/images/NHL_Team_Logos/...     #FFB81C   \n",
       "\n",
       "  secondary_hex tertiary_hex  \n",
       "0       #B9975B      #C1C6C8  \n",
       "1       #E2D6B5      #111111  \n",
       "2       #000000          NaN  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>twitter_handle</th>\n      <th>nhl_team</th>\n      <th>conference</th>\n      <th>2022_division</th>\n      <th>2021_division</th>\n      <th>expansion_type</th>\n      <th>2021_hashtag</th>\n      <th>other_hashtag</th>\n      <th>image</th>\n      <th>primary_hex</th>\n      <th>secondary_hex</th>\n      <th>tertiary_hex</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>@AnaheimDucks</td>\n      <td>Anaheim Ducks</td>\n      <td>Westernern</td>\n      <td>Pacific</td>\n      <td>West</td>\n      <td>Rest of League</td>\n      <td>#FlyTogether</td>\n      <td>#ducks</td>\n      <td>http://www.capsinfo.com/images/NHL_Team_Logos/...</td>\n      <td>#F47A38</td>\n      <td>#B9975B</td>\n      <td>#C1C6C8</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>@ArizonCoyotes</td>\n      <td>Arizona Coyotes</td>\n      <td>Western</td>\n      <td>Central</td>\n      <td>West</td>\n      <td>Rest of League</td>\n      <td>#Yotes</td>\n      <td>#coyotes</td>\n      <td>http://www.capsinfo.com/images/NHL_Team_Logos/...</td>\n      <td>#8C2633</td>\n      <td>#E2D6B5</td>\n      <td>#111111</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>@NHLBruins</td>\n      <td>Boston Bruins</td>\n      <td>Eastern</td>\n      <td>Atlantic</td>\n      <td>East</td>\n      <td>Rest of League</td>\n      <td>#NHLBruins</td>\n      <td>#bruins</td>\n      <td>http://www.capsinfo.com/images/NHL_Team_Logos/...</td>\n      <td>#FFB81C</td>\n      <td>#000000</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 81
    }
   ],
   "source": [
    "#Read in teams & accounts CSVs\n",
    "teams = pd.read_csv('nhl_app_teams.csv')\n",
    "accounts = pd.read_csv('nhl_app_accounts.csv')\n",
    "\n",
    "# if team is kraken, then kraken else rest of league\n",
    "#teams['expansion_type'] = np.where(teams.nhl_team.str.contains(\"Kraken\"), \"Kraken\", \"Rest of League\")\n",
    "\n",
    "teams.head(3)"
   ]
  },
  {
   "source": [
    "# Step 2: Get tweets and transform into dataframe"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\domen\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\ipykernel\\ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n",
      "C:\\Users\\domen\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\generic.py:5494: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[name] = value\n",
      "<ipython-input-80-e2e6b4865acf>:101: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  df['ANA'] = pd.np.where(df['clean_text'].str.contains('anaheim|ducks|#flytogether'), 'Anaheim Ducks', '0')\n",
      "<ipython-input-80-e2e6b4865acf>:101: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['ANA'] = pd.np.where(df['clean_text'].str.contains('anaheim|ducks|#flytogether'), 'Anaheim Ducks', '0')\n",
      "<ipython-input-80-e2e6b4865acf>:102: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  df['ARZ'] = pd.np.where(df['clean_text'].str.contains('arizona|coyotes|#yotes'), 'Arizona Coyotes', '0')\n",
      "<ipython-input-80-e2e6b4865acf>:102: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['ARZ'] = pd.np.where(df['clean_text'].str.contains('arizona|coyotes|#yotes'), 'Arizona Coyotes', '0')\n",
      "<ipython-input-80-e2e6b4865acf>:103: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  df['BOS'] = pd.np.where(df['clean_text'].str.contains('boston|bruins|#nhlbruins'), 'Boston Bruins', '0')\n",
      "<ipython-input-80-e2e6b4865acf>:103: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['BOS'] = pd.np.where(df['clean_text'].str.contains('boston|bruins|#nhlbruins'), 'Boston Bruins', '0')\n",
      "<ipython-input-80-e2e6b4865acf>:104: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  df['BUF'] = pd.np.where(df['clean_text'].str.contains('buffalo|sabres|#letsgobuffalo'), 'Buffalo Sabres', '0')\n",
      "<ipython-input-80-e2e6b4865acf>:105: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  df['CGY'] = pd.np.where(df['clean_text'].str.contains('calgary|flames|#cofred'), 'Calgary Flames', '0')\n",
      "<ipython-input-80-e2e6b4865acf>:106: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  df['CAR'] = pd.np.where(df['clean_text'].str.contains('carolina|hurricanes|#canes|#letsgocanes'), 'Carolina Hurricanes', '0')\n",
      "<ipython-input-80-e2e6b4865acf>:107: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  df['CHI'] = pd.np.where(df['clean_text'].str.contains('chicago|blackhawks|#blackhawks'), 'Chicago Blackhawks', '0')\n",
      "<ipython-input-80-e2e6b4865acf>:108: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  df['COL'] = pd.np.where(df['clean_text'].str.contains('colorado|avalanche|#GoAvsGo'), 'Colorado Avalanche', '0')\n",
      "<ipython-input-80-e2e6b4865acf>:109: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  df['CBJ'] = pd.np.where(df['clean_text'].str.contains('columbus|bluejackets|jackets|#CBJ'), 'Columbus Blue Jackets', '0')\n",
      "<ipython-input-80-e2e6b4865acf>:110: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  df['DAL'] = pd.np.where(df['clean_text'].str.contains('dallas|stars|#gostars'), 'Dallas Stars', '0')\n",
      "<ipython-input-80-e2e6b4865acf>:111: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  df['DET'] = pd.np.where(df['clean_text'].str.contains('detroit|redwings|#lgrw'), 'Detroit Red Wings', '0')\n",
      "<ipython-input-80-e2e6b4865acf>:112: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  df['EDM'] = pd.np.where(df['clean_text'].str.contains('edmonton|oilers|#oilers'), 'Edmonton Oilers', '0')\n",
      "<ipython-input-80-e2e6b4865acf>:113: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  df['FLA'] = pd.np.where(df['clean_text'].str.contains('florida|panthers|#flapanthers'), 'Florida Panthers', '0')\n",
      "<ipython-input-80-e2e6b4865acf>:114: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  df['LAK'] = pd.np.where(df['clean_text'].str.contains('los angeles|kings|#gokingsgo'), 'Los Angeles Kings', '0')\n",
      "<ipython-input-80-e2e6b4865acf>:115: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  df['MIN'] = pd.np.where(df['clean_text'].str.contains('minnesota|wild|#mnwild'), 'Minnesota Wild', '0')\n",
      "<ipython-input-80-e2e6b4865acf>:116: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  df['MTL'] = pd.np.where(df['clean_text'].str.contains('montreal|canadiens|habs|#gohabsgo'), 'Montreal Canadiens', '0')\n",
      "<ipython-input-80-e2e6b4865acf>:117: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  df['NSH'] = pd.np.where(df['clean_text'].str.contains('nashville|predators|#preds'), 'Nashville Predators', '0')\n",
      "<ipython-input-80-e2e6b4865acf>:118: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  df['NJD'] = pd.np.where(df['clean_text'].str.contains('new jersey|devils|#njdevils'), 'New Jersey Devils', '0')\n",
      "<ipython-input-80-e2e6b4865acf>:119: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  df['NYI'] = pd.np.where(df['clean_text'].str.contains('new york islanders|islanders|#isles'), 'New York Islanders', '0')\n",
      "<ipython-input-80-e2e6b4865acf>:120: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  df['NYR'] = pd.np.where(df['clean_text'].str.contains('new york rangers|rangers|#nyr'), 'New York Rangers', '0')\n",
      "<ipython-input-80-e2e6b4865acf>:121: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  df['OTT'] = pd.np.where(df['clean_text'].str.contains('ottawa|senators|sens|#gosensgo'), 'Ottawa Senators', '0')\n",
      "<ipython-input-80-e2e6b4865acf>:122: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  df['PHI'] = pd.np.where(df['clean_text'].str.contains('philadelphia|flyers|#anytimeanywhere'), 'Philadelphia Flyers', '0')\n",
      "<ipython-input-80-e2e6b4865acf>:123: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  df['PIT'] = pd.np.where(df['clean_text'].str.contains('pittsburgh|penguins|#pens|#letsgopens'), 'Pittsburgh Penguins', '0')\n",
      "<ipython-input-80-e2e6b4865acf>:124: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  df['SJS'] = pd.np.where(df['clean_text'].str.contains('san jose|sharks|#sjsharks'), 'San Jose Sharks', '0')\n",
      "<ipython-input-80-e2e6b4865acf>:125: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  df['SEA'] = pd.np.where(df['clean_text'].str.contains('seattle|kraken|#seakraken'), 'Seattle Kraken', '0')\n",
      "<ipython-input-80-e2e6b4865acf>:126: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  df['STL'] = pd.np.where(df['clean_text'].str.contains('stlouis|st. louis|st louis|blues|#stblues'), 'St Louis Blues', '0')\n",
      "<ipython-input-80-e2e6b4865acf>:127: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  df['TBL'] = pd.np.where(df['clean_text'].str.contains('tampa bay|lightning|tampa|#gobolts'), 'Tampa Bay Lightning', '0')\n",
      "<ipython-input-80-e2e6b4865acf>:128: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  df['TOR'] = pd.np.where(df['clean_text'].str.contains('toronto|maple leafs|#leafsforever'), 'Toronto Maple Leafs', '0')\n",
      "<ipython-input-80-e2e6b4865acf>:129: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  df['VAN'] = pd.np.where(df['clean_text'].str.contains('vancouver|canucks|#canucks'), 'Vancouver Canucks', '0')\n",
      "<ipython-input-80-e2e6b4865acf>:130: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  df['VGK'] = pd.np.where(df['clean_text'].str.contains('vegas|golden knights|knights|#vegasborn'), 'Vegas Golden Knights', '0')\n",
      "<ipython-input-80-e2e6b4865acf>:131: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  df['WSH'] = pd.np.where(df['clean_text'].str.contains('washington|capitals|#caps|#allcaps'), 'Washington Capitals', '0')\n",
      "<ipython-input-80-e2e6b4865acf>:132: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  df['WPG'] = pd.np.where(df['clean_text'].str.contains('winnipeg|jets|#gojetsgo'), 'Winnipeg Jets', '0')\n",
      "<ipython-input-80-e2e6b4865acf>:139: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['teams_concat'] = df.teams_concat.str.replace('0,|0|,0','').str.strip()\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                    id             user          created_at  \\\n",
       "0  1413869071695814658      CBJcoverage 2021-07-10 14:33:49   \n",
       "1  1413732444151422978      NHL_Watcher 2021-07-10 05:30:55   \n",
       "2  1413974338173292550    hockeyaddicts 2021-07-10 21:32:07   \n",
       "3  1413270173352562690     ClubsCrimson 2021-07-08 22:54:01   \n",
       "4  1412846290698969092  KrakenChronicle 2021-07-07 18:49:39   \n",
       "\n",
       "                                           full_text  \\\n",
       "0  Friedman: Jack Eichel trade now expected after...   \n",
       "1  Friedman in 33 Thoughts writes a Jack Eichel t...   \n",
       "2  NHL Rumors: Oilers, Blackhawks, Flyers, Sabres...   \n",
       "3  NHL Draft Order is set. Buffalo Sabres pick 1s...   \n",
       "4  The next look at who the #SeaKraken could take...   \n",
       "\n",
       "                                          clean_text  multiple_teams  \\\n",
       "0  friedman: jack eichel trade now expected after...               1   \n",
       "1  friedman in 33 thoughts writes a jack eichel t...               1   \n",
       "2  nhl rumors: oilers, blackhawks, flyers, sabres...               1   \n",
       "3  nhl draft order is set. buffalo sabres pick 1s...               1   \n",
       "4  the next look at who the #seakraken could take...               1   \n",
       "\n",
       "   no_matches                                       teams_concat  \\\n",
       "0           0  Anaheim Ducks,Boston Bruins,Calgary Flames,Los...   \n",
       "1           0  Anaheim Ducks,Boston Bruins,Calgary Flames,Los...   \n",
       "2           0  Arizona Coyotes,Buffalo Sabres,Carolina Hurric...   \n",
       "3           0      Arizona Coyotes,Buffalo Sabres,Seattle Kraken   \n",
       "4           0                     Arizona Coyotes,Seattle Kraken   \n",
       "\n",
       "  nhl_team_abbr         nhl_team  ... 2022_division 2021_division  \\\n",
       "0           ANA    Anaheim Ducks  ...       Pacific          West   \n",
       "1           ANA    Anaheim Ducks  ...       Pacific          West   \n",
       "2           ARZ  Arizona Coyotes  ...       Central          West   \n",
       "3           ARZ  Arizona Coyotes  ...       Central          West   \n",
       "4           ARZ  Arizona Coyotes  ...       Central          West   \n",
       "\n",
       "   expansion_type  2021_hashtag other_hashtag  \\\n",
       "0  Rest of League  #FlyTogether        #ducks   \n",
       "1  Rest of League  #FlyTogether        #ducks   \n",
       "2  Rest of League        #Yotes      #coyotes   \n",
       "3  Rest of League        #Yotes      #coyotes   \n",
       "4  Rest of League        #Yotes      #coyotes   \n",
       "\n",
       "                                               image primary_hex  \\\n",
       "0  http://www.capsinfo.com/images/NHL_Team_Logos/...     #F47A38   \n",
       "1  http://www.capsinfo.com/images/NHL_Team_Logos/...     #F47A38   \n",
       "2  http://www.capsinfo.com/images/NHL_Team_Logos/...     #8C2633   \n",
       "3  http://www.capsinfo.com/images/NHL_Team_Logos/...     #8C2633   \n",
       "4  http://www.capsinfo.com/images/NHL_Team_Logos/...     #8C2633   \n",
       "\n",
       "  secondary_hex tertiary_hex _merge  \n",
       "0       #B9975B      #C1C6C8   both  \n",
       "1       #B9975B      #C1C6C8   both  \n",
       "2       #E2D6B5      #111111   both  \n",
       "3       #E2D6B5      #111111   both  \n",
       "4       #E2D6B5      #111111   both  \n",
       "\n",
       "[5 rows x 22 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>user</th>\n      <th>created_at</th>\n      <th>full_text</th>\n      <th>clean_text</th>\n      <th>multiple_teams</th>\n      <th>no_matches</th>\n      <th>teams_concat</th>\n      <th>nhl_team_abbr</th>\n      <th>nhl_team</th>\n      <th>...</th>\n      <th>2022_division</th>\n      <th>2021_division</th>\n      <th>expansion_type</th>\n      <th>2021_hashtag</th>\n      <th>other_hashtag</th>\n      <th>image</th>\n      <th>primary_hex</th>\n      <th>secondary_hex</th>\n      <th>tertiary_hex</th>\n      <th>_merge</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1413869071695814658</td>\n      <td>CBJcoverage</td>\n      <td>2021-07-10 14:33:49</td>\n      <td>Friedman: Jack Eichel trade now expected after...</td>\n      <td>friedman: jack eichel trade now expected after...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>Anaheim Ducks,Boston Bruins,Calgary Flames,Los...</td>\n      <td>ANA</td>\n      <td>Anaheim Ducks</td>\n      <td>...</td>\n      <td>Pacific</td>\n      <td>West</td>\n      <td>Rest of League</td>\n      <td>#FlyTogether</td>\n      <td>#ducks</td>\n      <td>http://www.capsinfo.com/images/NHL_Team_Logos/...</td>\n      <td>#F47A38</td>\n      <td>#B9975B</td>\n      <td>#C1C6C8</td>\n      <td>both</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1413732444151422978</td>\n      <td>NHL_Watcher</td>\n      <td>2021-07-10 05:30:55</td>\n      <td>Friedman in 33 Thoughts writes a Jack Eichel t...</td>\n      <td>friedman in 33 thoughts writes a jack eichel t...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>Anaheim Ducks,Boston Bruins,Calgary Flames,Los...</td>\n      <td>ANA</td>\n      <td>Anaheim Ducks</td>\n      <td>...</td>\n      <td>Pacific</td>\n      <td>West</td>\n      <td>Rest of League</td>\n      <td>#FlyTogether</td>\n      <td>#ducks</td>\n      <td>http://www.capsinfo.com/images/NHL_Team_Logos/...</td>\n      <td>#F47A38</td>\n      <td>#B9975B</td>\n      <td>#C1C6C8</td>\n      <td>both</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1413974338173292550</td>\n      <td>hockeyaddicts</td>\n      <td>2021-07-10 21:32:07</td>\n      <td>NHL Rumors: Oilers, Blackhawks, Flyers, Sabres...</td>\n      <td>nhl rumors: oilers, blackhawks, flyers, sabres...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>Arizona Coyotes,Buffalo Sabres,Carolina Hurric...</td>\n      <td>ARZ</td>\n      <td>Arizona Coyotes</td>\n      <td>...</td>\n      <td>Central</td>\n      <td>West</td>\n      <td>Rest of League</td>\n      <td>#Yotes</td>\n      <td>#coyotes</td>\n      <td>http://www.capsinfo.com/images/NHL_Team_Logos/...</td>\n      <td>#8C2633</td>\n      <td>#E2D6B5</td>\n      <td>#111111</td>\n      <td>both</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1413270173352562690</td>\n      <td>ClubsCrimson</td>\n      <td>2021-07-08 22:54:01</td>\n      <td>NHL Draft Order is set. Buffalo Sabres pick 1s...</td>\n      <td>nhl draft order is set. buffalo sabres pick 1s...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>Arizona Coyotes,Buffalo Sabres,Seattle Kraken</td>\n      <td>ARZ</td>\n      <td>Arizona Coyotes</td>\n      <td>...</td>\n      <td>Central</td>\n      <td>West</td>\n      <td>Rest of League</td>\n      <td>#Yotes</td>\n      <td>#coyotes</td>\n      <td>http://www.capsinfo.com/images/NHL_Team_Logos/...</td>\n      <td>#8C2633</td>\n      <td>#E2D6B5</td>\n      <td>#111111</td>\n      <td>both</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1412846290698969092</td>\n      <td>KrakenChronicle</td>\n      <td>2021-07-07 18:49:39</td>\n      <td>The next look at who the #SeaKraken could take...</td>\n      <td>the next look at who the #seakraken could take...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>Arizona Coyotes,Seattle Kraken</td>\n      <td>ARZ</td>\n      <td>Arizona Coyotes</td>\n      <td>...</td>\n      <td>Central</td>\n      <td>West</td>\n      <td>Rest of League</td>\n      <td>#Yotes</td>\n      <td>#coyotes</td>\n      <td>http://www.capsinfo.com/images/NHL_Team_Logos/...</td>\n      <td>#8C2633</td>\n      <td>#E2D6B5</td>\n      <td>#111111</td>\n      <td>both</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 22 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 82
    }
   ],
   "source": [
    "select_hashtag_keyword = \"Keyword\"\n",
    "user_word_entry = \"NHL Expansion Draft\"\n",
    "select_language = \"English\"\n",
    "num_of_tweets = 1000\n",
    "\n",
    "# Run function 2: Get twitter data \n",
    "df_tweets, df_new = twitter_get(select_hashtag_keyword, select_language, user_word_entry, num_of_tweets)\n",
    "\n",
    "# Run function 3: Get classified nhl teams data\n",
    "df_nhl = classify_nhl_team(df_tweets)\n",
    "\n",
    "df_nhl.head(5)"
   ]
  },
  {
   "source": [
    "# Step 3: Basic exploratory data analysis (EDA)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\domen\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\ipykernel\\ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n  and should_run_async(code)\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'df_tweets_raw' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-a300b6ff5b32>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Rows:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_tweets_raw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'\\nColumns:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_tweets_raw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df_tweets_raw' is not defined"
     ]
    }
   ],
   "source": [
    "print('Rows:', df_tweets_raw.shape[0], '\\nColumns:', df_tweets_raw.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_tweet_length = df_tweets_raw.full_text.apply(len).max()\n",
    "print('Longest tweet is', max_tweet_length, 'characters long')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_date = df_tweets_raw.created_at.min()\n",
    "max_date = df_tweets_raw.created_at.max()\n",
    "\n",
    "print('Min. date: ', min_date, '\\nMax. date: ', max_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets_raw.describe(include='all')"
   ]
  },
  {
   "source": [
    "# Step 4: Feature Extraction (before text cleaning)\n",
    "* Count of Stopwords\n",
    "* Count of @ characters\n",
    "* Count of Hashtag characters\n",
    "* Count of Numeric characters\n",
    "* Count of Punctuation\n",
    "* Count of Emojis ðŸ˜œ\n",
    "* Count of Emoticons :-)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "#!pip install -q wordcloud\n",
    "#import wordcloud\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "import string\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "stop = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\domen\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\ipykernel\\ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n  and should_run_async(code)\n<>:53: DeprecationWarning: invalid escape sequence \\[\n<>:53: DeprecationWarning: invalid escape sequence \\[\n<ipython-input-25-c9fb39dd9e9a>:53: DeprecationWarning: invalid escape sequence \\[\n  text = re.sub('\\[.*?\\]', '', text) # removes text in square brackets\n"
     ]
    }
   ],
   "source": [
    "# Function 4\n",
    "#-----------------\n",
    "def feature_extract(df):\n",
    "    #TODO: add emoticons and emojis to this! and other punctuation\n",
    "\n",
    "    # Create pre-clean character count feature\n",
    "    df['character_ct'] = df.full_text.apply(lambda x: len(x))\n",
    "    # Create stopword count features (english and french)\n",
    "    df['stopword_en_ct'] = df.full_text.apply(lambda x: len([x for x in x.split() if x in stopwords_en]))\n",
    "    df['stopword_fr_ct'] = df.full_text.apply(lambda x: len([x for x in x.split() if x in stopwords_fr]))\n",
    "    # Create hashtag count feature\n",
    "    df['hashtag_ct'] = df.full_text.apply(lambda x: len([x for x in x.split() if x.startswith('#')]))\n",
    "    # Create link count feature\n",
    "    df['link_ct'] = df.full_text.apply(lambda x: len([x for x in x.split() if x.startswith('https')]))\n",
    "    # Create @ sign count feature\n",
    "    df['atsign_ct'] = df.full_text.apply(lambda x: len([x for x in x.split() if x.startswith('@')]))\n",
    "    # Create numeric count feature\n",
    "    df['numeric_ct'] = df.full_text.apply(lambda x: len([x for x in x.split() if x.isdigit()]))\n",
    "    # Create an uppercase count feature\n",
    "    df['uppercase_ct'] = df.full_text.apply(lambda x: len([x for x in x.split() if x.isupper()]))\n",
    "    return df\n",
    "\n",
    "# Function 5a\n",
    "#-------------\n",
    "def round1_text_clean(text):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                               u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U000024C2-\\U0001F251\"\n",
    "                               u\"\\U0001f926-\\U0001f937\"\n",
    "                               u\"\\U00010000-\\U0010ffff\"\n",
    "                               u\"\\u2640-\\u2642\"\n",
    "                               u\"\\u2600-\\u2B55\"\n",
    "                               u\"\\u200d\"\n",
    "                               u\"\\u23cf\"\n",
    "                               u\"\\u23e9\"\n",
    "                               u\"\\u231a\"\n",
    "                               u\"\\ufe0f\"  # dingbats\n",
    "                               u\"\\u3030\"\n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "    text = emoji_pattern.sub(r'', text) # remove emoji\n",
    "    text = ' ' + text # added space because there was some weirdness for first word (strip later)\n",
    "    text = text.lower() # convert all text to lowercase\n",
    "    text = re.sub(r'(\\s)@\\w+', '', text) # remove whole word if starts with @\n",
    "    text = re.sub(r'(\\s)\\w*\\d\\w*\\w+', '', text) # remove whole word if starts with number\n",
    "    text = re.sub(r'https\\:\\/\\/t\\.co\\/*\\w*', '', text) # remove https links\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text) # removes punctuation\n",
    "    text = re.sub('\\[.*?\\]', '', text) # removes text in square brackets\n",
    "    text = text.replace(\"â€™s\", '') # replace apostrophes with empty string\n",
    "    text = text.replace(\"'s\", '') # replace apostrophes with empty string\n",
    "    #text = re.sub('\\w*\\d\\w*', '', text) # remove whole word if starts with number\n",
    "    #text = re.sub(r'(\\s)#\\w+', '', text) # remove whole word if starts with #\n",
    "    text = text.strip() # strip text\n",
    "    return text\n",
    "\n",
    "# Function 5b\n",
    "#-------------\n",
    "text_clean_round1 = lambda x: round1_text_clean(x)\n",
    "\n",
    "# Function 6\n",
    "#-------------\n",
    "def text_clean_round2(text):\n",
    "    \"\"\"\n",
    "    A simple function to clean up the data. All the words that\n",
    "    are not designated as a stop word is then lemmatized after\n",
    "    encoding and basic regex parsing are performed.\n",
    "    \"\"\"\n",
    "    nltk.download('wordnet')\n",
    "    wnl = nltk.stem.WordNetLemmatizer()\n",
    "    stopwords = nltk.corpus.stopwords.words('english')\n",
    "    text = (unicodedata.normalize('NFKD', text)\n",
    "    .encode('ascii', 'ignore')\n",
    "    .decode('utf-8', 'ignore'))\n",
    "    words = re.sub(r'[^\\w\\s]', '', text).split()\n",
    "    return [wnl.lemmatize(word) for word in words if word not in stopwords]\n",
    "\n",
    "# Function 7\n",
    "#-------------\n",
    "def text_clean_round3(text):\n",
    "    #TODO: add emoticons and emojis to this!\n",
    "    # Load in stopwords\n",
    "    stopwords_en = nltk.corpus.stopwords.words('english')\n",
    "    stopwords_fr = nltk.corpus.stopwords.words('french')\n",
    "    stopwords = stopwords_en + stopwords_fr\n",
    "    # Create pre-clean character count feature\n",
    "    text = text.apply(lambda x: \" \".join(x for x in x.split() if x not in stopwords))\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\domen\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\ipykernel\\ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n  and should_run_async(code)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                    id           user          created_at  \\\n",
       "0  1413869071695814658    CBJcoverage 2021-07-10 14:33:49   \n",
       "1  1413732444151422978    NHL_Watcher 2021-07-10 05:30:55   \n",
       "2  1411070238150434818       mayorNHL 2021-07-02 21:12:15   \n",
       "3  1413974338173292550  hockeyaddicts 2021-07-10 21:32:07   \n",
       "4  1413270173352562690   ClubsCrimson 2021-07-08 22:54:01   \n",
       "\n",
       "                                           full_text  \\\n",
       "0  Friedman: Jack Eichel trade now expected after...   \n",
       "1  Friedman in 33 Thoughts writes a Jack Eichel t...   \n",
       "2  (new post) NHL RADIO REPLAY: Mayorâ€™s Minutes\\n...   \n",
       "3  NHL Rumors: Oilers, Blackhawks, Flyers, Sabres...   \n",
       "4  NHL Draft Order is set. Buffalo Sabres pick 1s...   \n",
       "\n",
       "                                          clean_text  multiple_teams  \\\n",
       "0  friedman jack eichel trade expected expansion ...               1   \n",
       "1  friedman thoughts writes jack eichel trade lik...               1   \n",
       "2  new post nhl radio replay mayor minutes topics...               1   \n",
       "3  nhl rumors oilers blackhawks flyers sabres hur...               1   \n",
       "4  nhl draft order set buffalo sabres pick expans...               1   \n",
       "\n",
       "   no_matches                                       teams_concat  \\\n",
       "0           0  Anaheim Ducks,Boston Bruins,Calgary Flames,Los...   \n",
       "1           0  Anaheim Ducks,Boston Bruins,Calgary Flames,Los...   \n",
       "2           0     Anaheim Ducks,Los Angeles Kings,Seattle Kraken   \n",
       "3           0  Arizona Coyotes,Buffalo Sabres,Carolina Hurric...   \n",
       "4           0      Arizona Coyotes,Buffalo Sabres,Seattle Kraken   \n",
       "\n",
       "  nhl_team_abbr         nhl_team  ... tertiary_hex _merge character_ct  \\\n",
       "0           ANA    Anaheim Ducks  ...      #C1C6C8   both          210   \n",
       "1           ANA    Anaheim Ducks  ...      #C1C6C8   both          224   \n",
       "2           ANA    Anaheim Ducks  ...      #C1C6C8   both          281   \n",
       "3           ARZ  Arizona Coyotes  ...      #111111   both          269   \n",
       "4           ARZ  Arizona Coyotes  ...      #111111   both          250   \n",
       "\n",
       "  stopword_en_ct stopword_fr_ct hashtag_ct link_ct atsign_ct numeric_ct  \\\n",
       "0              8              1          1       1         0          0   \n",
       "1             13              1          0       0         0          1   \n",
       "2              1              0          0       2         0          0   \n",
       "3              6              0          0       2         0          0   \n",
       "4             10              1          0       1         1          0   \n",
       "\n",
       "  uppercase_ct  \n",
       "0            1  \n",
       "1            1  \n",
       "2            7  \n",
       "3            2  \n",
       "4            2  \n",
       "\n",
       "[5 rows x 29 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>user</th>\n      <th>created_at</th>\n      <th>full_text</th>\n      <th>clean_text</th>\n      <th>multiple_teams</th>\n      <th>no_matches</th>\n      <th>teams_concat</th>\n      <th>nhl_team_abbr</th>\n      <th>nhl_team</th>\n      <th>...</th>\n      <th>tertiary_hex</th>\n      <th>_merge</th>\n      <th>character_ct</th>\n      <th>stopword_en_ct</th>\n      <th>stopword_fr_ct</th>\n      <th>hashtag_ct</th>\n      <th>link_ct</th>\n      <th>atsign_ct</th>\n      <th>numeric_ct</th>\n      <th>uppercase_ct</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1413869071695814658</td>\n      <td>CBJcoverage</td>\n      <td>2021-07-10 14:33:49</td>\n      <td>Friedman: Jack Eichel trade now expected after...</td>\n      <td>friedman jack eichel trade expected expansion ...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>Anaheim Ducks,Boston Bruins,Calgary Flames,Los...</td>\n      <td>ANA</td>\n      <td>Anaheim Ducks</td>\n      <td>...</td>\n      <td>#C1C6C8</td>\n      <td>both</td>\n      <td>210</td>\n      <td>8</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1413732444151422978</td>\n      <td>NHL_Watcher</td>\n      <td>2021-07-10 05:30:55</td>\n      <td>Friedman in 33 Thoughts writes a Jack Eichel t...</td>\n      <td>friedman thoughts writes jack eichel trade lik...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>Anaheim Ducks,Boston Bruins,Calgary Flames,Los...</td>\n      <td>ANA</td>\n      <td>Anaheim Ducks</td>\n      <td>...</td>\n      <td>#C1C6C8</td>\n      <td>both</td>\n      <td>224</td>\n      <td>13</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1411070238150434818</td>\n      <td>mayorNHL</td>\n      <td>2021-07-02 21:12:15</td>\n      <td>(new post) NHL RADIO REPLAY: Mayorâ€™s Minutes\\n...</td>\n      <td>new post nhl radio replay mayor minutes topics...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>Anaheim Ducks,Los Angeles Kings,Seattle Kraken</td>\n      <td>ANA</td>\n      <td>Anaheim Ducks</td>\n      <td>...</td>\n      <td>#C1C6C8</td>\n      <td>both</td>\n      <td>281</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1413974338173292550</td>\n      <td>hockeyaddicts</td>\n      <td>2021-07-10 21:32:07</td>\n      <td>NHL Rumors: Oilers, Blackhawks, Flyers, Sabres...</td>\n      <td>nhl rumors oilers blackhawks flyers sabres hur...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>Arizona Coyotes,Buffalo Sabres,Carolina Hurric...</td>\n      <td>ARZ</td>\n      <td>Arizona Coyotes</td>\n      <td>...</td>\n      <td>#111111</td>\n      <td>both</td>\n      <td>269</td>\n      <td>6</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1413270173352562690</td>\n      <td>ClubsCrimson</td>\n      <td>2021-07-08 22:54:01</td>\n      <td>NHL Draft Order is set. Buffalo Sabres pick 1s...</td>\n      <td>nhl draft order set buffalo sabres pick expans...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>Arizona Coyotes,Buffalo Sabres,Seattle Kraken</td>\n      <td>ARZ</td>\n      <td>Arizona Coyotes</td>\n      <td>...</td>\n      <td>#111111</td>\n      <td>both</td>\n      <td>250</td>\n      <td>10</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 29 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "# Run function #4: Feature extraction\n",
    "df_nhl = feature_extract(df_nhl)\n",
    "\n",
    "# Run function #5: Round 1 text cleaning (convert to lower, remove numbers, @, punctuation, numbers. etc.)\n",
    "df_nhl['clean_text'] = df_nhl.clean_text.apply(text_clean_round1)\n",
    "\n",
    "## Run function #7: Round 3 text cleaning (remove stop words)\n",
    "df_nhl.clean_text  = text_clean_round3(df_nhl.clean_text)\n",
    "\n",
    "df_nhl.head(5)"
   ]
  },
  {
   "source": [
    "## Part 5: Sentiment Analysis\n",
    "* Import VADER functions\n",
    "* Apply VADER sentiment analyzer to raw tweets, create output columns"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\domen\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\ipykernel\\ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n  and should_run_async(code)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                     id             user          created_at  \\\n",
       "0   1413869071695814658      CBJcoverage 2021-07-10 14:33:49   \n",
       "1   1413732444151422978      NHL_Watcher 2021-07-10 05:30:55   \n",
       "2   1413974338173292550    hockeyaddicts 2021-07-10 21:32:07   \n",
       "3   1413270173352562690     ClubsCrimson 2021-07-08 22:54:01   \n",
       "4   1412846290698969092  KrakenChronicle 2021-07-07 18:49:39   \n",
       "..                  ...              ...                 ...   \n",
       "95  1413732444151422978      NHL_Watcher 2021-07-10 05:30:55   \n",
       "96  1414305376984522762         muggsy34 2021-07-11 19:27:33   \n",
       "97  1414258128963751937      pinejournal 2021-07-11 16:19:48   \n",
       "98  1414257689513840642  CreaseAndAssist 2021-07-11 16:18:03   \n",
       "99  1414134669499674624          PB_News 2021-07-11 08:09:13   \n",
       "\n",
       "                                            full_text  \\\n",
       "0   Friedman: Jack Eichel trade now expected after...   \n",
       "1   Friedman in 33 Thoughts writes a Jack Eichel t...   \n",
       "2   NHL Rumors: Oilers, Blackhawks, Flyers, Sabres...   \n",
       "3   NHL Draft Order is set. Buffalo Sabres pick 1s...   \n",
       "4   The next look at who the #SeaKraken could take...   \n",
       "..                                                ...   \n",
       "95  Friedman in 33 Thoughts writes a Jack Eichel t...   \n",
       "96  @RussoHockey I just noticed how â€œMinnesotaâ€ th...   \n",
       "97  A look at who Wild could lose in NHL expansion...   \n",
       "98  #mnwild I wonder when Wild fans will stop tryi...   \n",
       "99  A look at who Wild could lose in NHL expansion...   \n",
       "\n",
       "                                           clean_text  multiple_teams  \\\n",
       "0   friedman: jack eichel trade now expected after...               1   \n",
       "1   friedman in 33 thoughts writes a jack eichel t...               1   \n",
       "2   nhl rumors: oilers, blackhawks, flyers, sabres...               1   \n",
       "3   nhl draft order is set. buffalo sabres pick 1s...               1   \n",
       "4   the next look at who the #seakraken could take...               1   \n",
       "..                                                ...             ...   \n",
       "95  friedman in 33 thoughts writes a jack eichel t...               1   \n",
       "96  @russohockey i just noticed how â€œminnesotaâ€ th...               0   \n",
       "97  a look at who wild could lose in nhl expansion...               0   \n",
       "98  #mnwild i wonder when wild fans will stop tryi...               0   \n",
       "99  a look at who wild could lose in nhl expansion...               0   \n",
       "\n",
       "    no_matches                                       teams_concat  \\\n",
       "0            0  Anaheim Ducks,Boston Bruins,Calgary Flames,Los...   \n",
       "1            0  Anaheim Ducks,Boston Bruins,Calgary Flames,Los...   \n",
       "2            0  Arizona Coyotes,Buffalo Sabres,Carolina Hurric...   \n",
       "3            0      Arizona Coyotes,Buffalo Sabres,Seattle Kraken   \n",
       "4            0                     Arizona Coyotes,Seattle Kraken   \n",
       "..         ...                                                ...   \n",
       "95           0  Anaheim Ducks,Boston Bruins,Calgary Flames,Los...   \n",
       "96           0                                     Minnesota Wild   \n",
       "97           0                                     Minnesota Wild   \n",
       "98           0                                     Minnesota Wild   \n",
       "99           0                                     Minnesota Wild   \n",
       "\n",
       "   nhl_team_abbr           nhl_team  ... 2022_division 2021_division  \\\n",
       "0            ANA      Anaheim Ducks  ...       Pacific          West   \n",
       "1            ANA      Anaheim Ducks  ...       Pacific          West   \n",
       "2            ARZ    Arizona Coyotes  ...       Central          West   \n",
       "3            ARZ    Arizona Coyotes  ...       Central          West   \n",
       "4            ARZ    Arizona Coyotes  ...       Central          West   \n",
       "..           ...                ...  ...           ...           ...   \n",
       "95           LAK  Los Angeles Kings  ...       Pacific          West   \n",
       "96           MIN     Minnesota Wild  ...       Central          West   \n",
       "97           MIN     Minnesota Wild  ...       Central          West   \n",
       "98           MIN     Minnesota Wild  ...       Central          West   \n",
       "99           MIN     Minnesota Wild  ...       Central          West   \n",
       "\n",
       "    expansion_type  2021_hashtag other_hashtag  \\\n",
       "0   Rest of League  #FlyTogether        #ducks   \n",
       "1   Rest of League  #FlyTogether        #ducks   \n",
       "2   Rest of League        #Yotes      #coyotes   \n",
       "3   Rest of League        #Yotes      #coyotes   \n",
       "4   Rest of League        #Yotes      #coyotes   \n",
       "..             ...           ...           ...   \n",
       "95  Rest of League    #GoKingsGo        #kings   \n",
       "96  Rest of League       #MNWild         #wild   \n",
       "97  Rest of League       #MNWild         #wild   \n",
       "98  Rest of League       #MNWild         #wild   \n",
       "99  Rest of League       #MNWild         #wild   \n",
       "\n",
       "                                                image primary_hex  \\\n",
       "0   http://www.capsinfo.com/images/NHL_Team_Logos/...     #F47A38   \n",
       "1   http://www.capsinfo.com/images/NHL_Team_Logos/...     #F47A38   \n",
       "2   http://www.capsinfo.com/images/NHL_Team_Logos/...     #8C2633   \n",
       "3   http://www.capsinfo.com/images/NHL_Team_Logos/...     #8C2633   \n",
       "4   http://www.capsinfo.com/images/NHL_Team_Logos/...     #8C2633   \n",
       "..                                                ...         ...   \n",
       "95  http://www.capsinfo.com/images/NHL_Team_Logos/...     #111111   \n",
       "96  http://www.capsinfo.com/images/NHL_Team_Logos/...     #154734   \n",
       "97  http://www.capsinfo.com/images/NHL_Team_Logos/...     #154734   \n",
       "98  http://www.capsinfo.com/images/NHL_Team_Logos/...     #154734   \n",
       "99  http://www.capsinfo.com/images/NHL_Team_Logos/...     #154734   \n",
       "\n",
       "   secondary_hex tertiary_hex _merge  \n",
       "0        #B9975B      #C1C6C8   both  \n",
       "1        #B9975B      #C1C6C8   both  \n",
       "2        #E2D6B5      #111111   both  \n",
       "3        #E2D6B5      #111111   both  \n",
       "4        #E2D6B5      #111111   both  \n",
       "..           ...          ...    ...  \n",
       "95       #A2AAAD      #572A84   both  \n",
       "96       #A6192E      #EAAA00   both  \n",
       "97       #A6192E      #EAAA00   both  \n",
       "98       #A6192E      #EAAA00   both  \n",
       "99       #A6192E      #EAAA00   both  \n",
       "\n",
       "[100 rows x 22 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>user</th>\n      <th>created_at</th>\n      <th>full_text</th>\n      <th>clean_text</th>\n      <th>multiple_teams</th>\n      <th>no_matches</th>\n      <th>teams_concat</th>\n      <th>nhl_team_abbr</th>\n      <th>nhl_team</th>\n      <th>...</th>\n      <th>2022_division</th>\n      <th>2021_division</th>\n      <th>expansion_type</th>\n      <th>2021_hashtag</th>\n      <th>other_hashtag</th>\n      <th>image</th>\n      <th>primary_hex</th>\n      <th>secondary_hex</th>\n      <th>tertiary_hex</th>\n      <th>_merge</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1413869071695814658</td>\n      <td>CBJcoverage</td>\n      <td>2021-07-10 14:33:49</td>\n      <td>Friedman: Jack Eichel trade now expected after...</td>\n      <td>friedman: jack eichel trade now expected after...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>Anaheim Ducks,Boston Bruins,Calgary Flames,Los...</td>\n      <td>ANA</td>\n      <td>Anaheim Ducks</td>\n      <td>...</td>\n      <td>Pacific</td>\n      <td>West</td>\n      <td>Rest of League</td>\n      <td>#FlyTogether</td>\n      <td>#ducks</td>\n      <td>http://www.capsinfo.com/images/NHL_Team_Logos/...</td>\n      <td>#F47A38</td>\n      <td>#B9975B</td>\n      <td>#C1C6C8</td>\n      <td>both</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1413732444151422978</td>\n      <td>NHL_Watcher</td>\n      <td>2021-07-10 05:30:55</td>\n      <td>Friedman in 33 Thoughts writes a Jack Eichel t...</td>\n      <td>friedman in 33 thoughts writes a jack eichel t...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>Anaheim Ducks,Boston Bruins,Calgary Flames,Los...</td>\n      <td>ANA</td>\n      <td>Anaheim Ducks</td>\n      <td>...</td>\n      <td>Pacific</td>\n      <td>West</td>\n      <td>Rest of League</td>\n      <td>#FlyTogether</td>\n      <td>#ducks</td>\n      <td>http://www.capsinfo.com/images/NHL_Team_Logos/...</td>\n      <td>#F47A38</td>\n      <td>#B9975B</td>\n      <td>#C1C6C8</td>\n      <td>both</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1413974338173292550</td>\n      <td>hockeyaddicts</td>\n      <td>2021-07-10 21:32:07</td>\n      <td>NHL Rumors: Oilers, Blackhawks, Flyers, Sabres...</td>\n      <td>nhl rumors: oilers, blackhawks, flyers, sabres...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>Arizona Coyotes,Buffalo Sabres,Carolina Hurric...</td>\n      <td>ARZ</td>\n      <td>Arizona Coyotes</td>\n      <td>...</td>\n      <td>Central</td>\n      <td>West</td>\n      <td>Rest of League</td>\n      <td>#Yotes</td>\n      <td>#coyotes</td>\n      <td>http://www.capsinfo.com/images/NHL_Team_Logos/...</td>\n      <td>#8C2633</td>\n      <td>#E2D6B5</td>\n      <td>#111111</td>\n      <td>both</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1413270173352562690</td>\n      <td>ClubsCrimson</td>\n      <td>2021-07-08 22:54:01</td>\n      <td>NHL Draft Order is set. Buffalo Sabres pick 1s...</td>\n      <td>nhl draft order is set. buffalo sabres pick 1s...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>Arizona Coyotes,Buffalo Sabres,Seattle Kraken</td>\n      <td>ARZ</td>\n      <td>Arizona Coyotes</td>\n      <td>...</td>\n      <td>Central</td>\n      <td>West</td>\n      <td>Rest of League</td>\n      <td>#Yotes</td>\n      <td>#coyotes</td>\n      <td>http://www.capsinfo.com/images/NHL_Team_Logos/...</td>\n      <td>#8C2633</td>\n      <td>#E2D6B5</td>\n      <td>#111111</td>\n      <td>both</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1412846290698969092</td>\n      <td>KrakenChronicle</td>\n      <td>2021-07-07 18:49:39</td>\n      <td>The next look at who the #SeaKraken could take...</td>\n      <td>the next look at who the #seakraken could take...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>Arizona Coyotes,Seattle Kraken</td>\n      <td>ARZ</td>\n      <td>Arizona Coyotes</td>\n      <td>...</td>\n      <td>Central</td>\n      <td>West</td>\n      <td>Rest of League</td>\n      <td>#Yotes</td>\n      <td>#coyotes</td>\n      <td>http://www.capsinfo.com/images/NHL_Team_Logos/...</td>\n      <td>#8C2633</td>\n      <td>#E2D6B5</td>\n      <td>#111111</td>\n      <td>both</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>95</th>\n      <td>1413732444151422978</td>\n      <td>NHL_Watcher</td>\n      <td>2021-07-10 05:30:55</td>\n      <td>Friedman in 33 Thoughts writes a Jack Eichel t...</td>\n      <td>friedman in 33 thoughts writes a jack eichel t...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>Anaheim Ducks,Boston Bruins,Calgary Flames,Los...</td>\n      <td>LAK</td>\n      <td>Los Angeles Kings</td>\n      <td>...</td>\n      <td>Pacific</td>\n      <td>West</td>\n      <td>Rest of League</td>\n      <td>#GoKingsGo</td>\n      <td>#kings</td>\n      <td>http://www.capsinfo.com/images/NHL_Team_Logos/...</td>\n      <td>#111111</td>\n      <td>#A2AAAD</td>\n      <td>#572A84</td>\n      <td>both</td>\n    </tr>\n    <tr>\n      <th>96</th>\n      <td>1414305376984522762</td>\n      <td>muggsy34</td>\n      <td>2021-07-11 19:27:33</td>\n      <td>@RussoHockey I just noticed how â€œMinnesotaâ€ th...</td>\n      <td>@russohockey i just noticed how â€œminnesotaâ€ th...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Minnesota Wild</td>\n      <td>MIN</td>\n      <td>Minnesota Wild</td>\n      <td>...</td>\n      <td>Central</td>\n      <td>West</td>\n      <td>Rest of League</td>\n      <td>#MNWild</td>\n      <td>#wild</td>\n      <td>http://www.capsinfo.com/images/NHL_Team_Logos/...</td>\n      <td>#154734</td>\n      <td>#A6192E</td>\n      <td>#EAAA00</td>\n      <td>both</td>\n    </tr>\n    <tr>\n      <th>97</th>\n      <td>1414258128963751937</td>\n      <td>pinejournal</td>\n      <td>2021-07-11 16:19:48</td>\n      <td>A look at who Wild could lose in NHL expansion...</td>\n      <td>a look at who wild could lose in nhl expansion...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Minnesota Wild</td>\n      <td>MIN</td>\n      <td>Minnesota Wild</td>\n      <td>...</td>\n      <td>Central</td>\n      <td>West</td>\n      <td>Rest of League</td>\n      <td>#MNWild</td>\n      <td>#wild</td>\n      <td>http://www.capsinfo.com/images/NHL_Team_Logos/...</td>\n      <td>#154734</td>\n      <td>#A6192E</td>\n      <td>#EAAA00</td>\n      <td>both</td>\n    </tr>\n    <tr>\n      <th>98</th>\n      <td>1414257689513840642</td>\n      <td>CreaseAndAssist</td>\n      <td>2021-07-11 16:18:03</td>\n      <td>#mnwild I wonder when Wild fans will stop tryi...</td>\n      <td>#mnwild i wonder when wild fans will stop tryi...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Minnesota Wild</td>\n      <td>MIN</td>\n      <td>Minnesota Wild</td>\n      <td>...</td>\n      <td>Central</td>\n      <td>West</td>\n      <td>Rest of League</td>\n      <td>#MNWild</td>\n      <td>#wild</td>\n      <td>http://www.capsinfo.com/images/NHL_Team_Logos/...</td>\n      <td>#154734</td>\n      <td>#A6192E</td>\n      <td>#EAAA00</td>\n      <td>both</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>1414134669499674624</td>\n      <td>PB_News</td>\n      <td>2021-07-11 08:09:13</td>\n      <td>A look at who Wild could lose in NHL expansion...</td>\n      <td>a look at who wild could lose in nhl expansion...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Minnesota Wild</td>\n      <td>MIN</td>\n      <td>Minnesota Wild</td>\n      <td>...</td>\n      <td>Central</td>\n      <td>West</td>\n      <td>Rest of League</td>\n      <td>#MNWild</td>\n      <td>#wild</td>\n      <td>http://www.capsinfo.com/images/NHL_Team_Logos/...</td>\n      <td>#154734</td>\n      <td>#A6192E</td>\n      <td>#EAAA00</td>\n      <td>both</td>\n    </tr>\n  </tbody>\n</table>\n<p>100 rows Ã— 22 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 84
    }
   ],
   "source": [
    "# Create a copy to preserve the raw data\n",
    "df_nhl_copy = df_nhl.copy()\n",
    "\n",
    "df_nhl_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\domen\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\ipykernel\\ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n  and should_run_async(code)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "                      id             user          created_at  \\\n672  1413192587364737025  4EverBlueshirts 2021-07-08 17:45:43   \n770  1411138243328946183           xHalfy 2021-07-03 01:42:29   \n469  1411435370324058118  EveryBrokenWave 2021-07-03 21:23:10   \n429  1412607473668739078   SeaTimesSports 2021-07-07 03:00:41   \n128  1411084249294262274       jetcityice 2021-07-02 22:07:56   \n\n                                             full_text  \\\n672  #NHL what if...\\n\\nWhat if Jack Eichel has alr...   \n770  Honestly I just want this nhl season to be ove...   \n469  Kraken troll other NHL teams with expansion dr...   \n429  It seemed for months as if the Kraken's expans...   \n128  2021 NHL Expansion Draft ramifications for #Se...   \n\n                                            clean_text  multiple_teams  \\\n672  nhl jack eichel already traded deal agreed fin...               0   \n770  honestly want nhl season get free agency crazy...               0   \n469  kraken troll nhl teams expansion draft looming...               0   \n429  seemed months krakens expansion draft picks li...               1   \n128  nhl expansion draft ramifications seakraken ne...               1   \n\n     no_matches                                       teams_concat  \\\n672           1                                                      \n770           1                                                      \n469           0                                     Seattle Kraken   \n429           0  Montreal Canadiens,Seattle Kraken,Tampa Bay Li...   \n128           0                      Minnesota Wild,Seattle Kraken   \n\n    nhl_team_abbr        nhl_team  ... stopword_fr_ct hashtag_ct link_ct  \\\n672       Unknown         Unknown  ...              0          1       0   \n770       Unknown         Unknown  ...              0          0       0   \n469           SEA  Seattle Kraken  ...              0          0       1   \n429           SEA  Seattle Kraken  ...              1          0       1   \n128           MIN  Minnesota Wild  ...              0          2       1   \n\n    atsign_ct numeric_ct uppercase_ct positive_score negative_score  \\\n672         0          0            1          0.042          0.000   \n770         0          0            1          0.245          0.077   \n469         1          0            1          0.000          0.120   \n429         0          0            0          0.038          0.000   \n128         0          1            3          0.057          0.000   \n\n    neutral_score compound_score  \n672         0.958         0.1406  \n770         0.677         0.6369  \n469         0.880        -0.1280  \n429         0.962         0.1531  \n128         0.943         0.3818  \n\n[5 rows x 33 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>user</th>\n      <th>created_at</th>\n      <th>full_text</th>\n      <th>clean_text</th>\n      <th>multiple_teams</th>\n      <th>no_matches</th>\n      <th>teams_concat</th>\n      <th>nhl_team_abbr</th>\n      <th>nhl_team</th>\n      <th>...</th>\n      <th>stopword_fr_ct</th>\n      <th>hashtag_ct</th>\n      <th>link_ct</th>\n      <th>atsign_ct</th>\n      <th>numeric_ct</th>\n      <th>uppercase_ct</th>\n      <th>positive_score</th>\n      <th>negative_score</th>\n      <th>neutral_score</th>\n      <th>compound_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>672</th>\n      <td>1413192587364737025</td>\n      <td>4EverBlueshirts</td>\n      <td>2021-07-08 17:45:43</td>\n      <td>#NHL what if...\\n\\nWhat if Jack Eichel has alr...</td>\n      <td>nhl jack eichel already traded deal agreed fin...</td>\n      <td>0</td>\n      <td>1</td>\n      <td></td>\n      <td>Unknown</td>\n      <td>Unknown</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0.042</td>\n      <td>0.000</td>\n      <td>0.958</td>\n      <td>0.1406</td>\n    </tr>\n    <tr>\n      <th>770</th>\n      <td>1411138243328946183</td>\n      <td>xHalfy</td>\n      <td>2021-07-03 01:42:29</td>\n      <td>Honestly I just want this nhl season to be ove...</td>\n      <td>honestly want nhl season get free agency crazy...</td>\n      <td>0</td>\n      <td>1</td>\n      <td></td>\n      <td>Unknown</td>\n      <td>Unknown</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0.245</td>\n      <td>0.077</td>\n      <td>0.677</td>\n      <td>0.6369</td>\n    </tr>\n    <tr>\n      <th>469</th>\n      <td>1411435370324058118</td>\n      <td>EveryBrokenWave</td>\n      <td>2021-07-03 21:23:10</td>\n      <td>Kraken troll other NHL teams with expansion dr...</td>\n      <td>kraken troll nhl teams expansion draft looming...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Seattle Kraken</td>\n      <td>SEA</td>\n      <td>Seattle Kraken</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0.000</td>\n      <td>0.120</td>\n      <td>0.880</td>\n      <td>-0.1280</td>\n    </tr>\n    <tr>\n      <th>429</th>\n      <td>1412607473668739078</td>\n      <td>SeaTimesSports</td>\n      <td>2021-07-07 03:00:41</td>\n      <td>It seemed for months as if the Kraken's expans...</td>\n      <td>seemed months krakens expansion draft picks li...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>Montreal Canadiens,Seattle Kraken,Tampa Bay Li...</td>\n      <td>SEA</td>\n      <td>Seattle Kraken</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.038</td>\n      <td>0.000</td>\n      <td>0.962</td>\n      <td>0.1531</td>\n    </tr>\n    <tr>\n      <th>128</th>\n      <td>1411084249294262274</td>\n      <td>jetcityice</td>\n      <td>2021-07-02 22:07:56</td>\n      <td>2021 NHL Expansion Draft ramifications for #Se...</td>\n      <td>nhl expansion draft ramifications seakraken ne...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>Minnesota Wild,Seattle Kraken</td>\n      <td>MIN</td>\n      <td>Minnesota Wild</td>\n      <td>...</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>3</td>\n      <td>0.057</td>\n      <td>0.000</td>\n      <td>0.943</td>\n      <td>0.3818</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 33 columns</p>\n</div>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "# Credit: https://jackmckew.dev/sentiment-analysis-text-cleaning-in-python-with-vader.html\n",
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "sid_analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "def get_sentiment(text:str, analyser,desired_type:str='pos'):\n",
    "    # Get sentiment from text\n",
    "    sentiment_score = analyser.polarity_scores(text)\n",
    "    return sentiment_score[desired_type]\n",
    "\n",
    "# Get Sentiment scores\n",
    "def get_sentiment_scores(df, data_column):\n",
    "    df[f'positive_score'] = df[data_column].astype(str).apply(lambda x: get_sentiment(x,sid_analyzer,'pos'))\n",
    "    df[f'negative_score'] = df[data_column].astype(str).apply(lambda x: get_sentiment(x,sid_analyzer,'neg'))\n",
    "    df[f'neutral_score'] = df[data_column].astype(str).apply(lambda x: get_sentiment(x,sid_analyzer,'neu'))\n",
    "    df[f'compound_score'] = df[data_column].astype(str).apply(lambda x: get_sentiment(x,sid_analyzer,'compound'))\n",
    "    return df\n",
    "\n",
    "\n",
    "text_sentiment = get_sentiment_scores(df_nhl, 'full_text')\n",
    "\n",
    "display(text_sentiment.sample(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\domen\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\ipykernel\\ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n  and should_run_async(code)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "                      id            user          created_at  \\\n262  1413634069540134912        walshy66 2021-07-09 23:00:00   \n149  1411416504042655744  NathanGraviteh 2021-07-03 20:08:12   \n494  1412441045133103114    StLouisBlues 2021-07-06 15:59:21   \n409  1412872575970017282   nhl_tradetalk 2021-07-07 20:34:06   \n69   1411363125538983939     AntGenocide 2021-07-03 16:36:05   \n\n                                             full_text  \\\n262  NEW PODCAST: Tampa win, expansion draft, and t...   \n149  *NEW* *VIDEO*\\n\\nTODAY I Predict the ENITRE Se...   \n494  The @NHL #ExpansionDraft is almost here! \\n\\nH...   \n409  GM David Poile says the Nashville Predators ar...   \n69   Am the only one ready for NHL playoffs to be o...   \n\n                                            clean_text  multiple_teams  \\\n262  new podcast tampa win expansion draft tidbits ...               1   \n149  new video today predict enitre seattle kraken ...               1   \n494  expansiondraft almost many players seattle sel...               1   \n409  gm david poile says nashville predators lookin...               1   \n69   one ready nhl playoffs get expansion draft off...               0   \n\n     no_matches                                      teams_concat  \\\n262           0           Pittsburgh Penguins,Tampa Bay Lightning   \n149           0  Montreal Canadiens,Seattle Kraken,St Louis Blues   \n494           0                     Seattle Kraken,St Louis Blues   \n409           0                Nashville Predators,Seattle Kraken   \n69            0                                      Dallas Stars   \n\n    nhl_team_abbr             nhl_team  ... hashtag_ct link_ct atsign_ct  \\\n262           PIT  Pittsburgh Penguins  ...          2       2         0   \n149           MTL   Montreal Canadiens  ...          3       2         0   \n494           STL       St Louis Blues  ...          2       1         1   \n409           SEA       Seattle Kraken  ...          0       1         0   \n69            DAL         Dallas Stars  ...          0       0         0   \n\n    numeric_ct uppercase_ct positive_score negative_score neutral_score  \\\n262          0            3          0.226            0.0         0.774   \n149          1            9          0.000            0.0         1.000   \n494          0            1          0.097            0.0         0.903   \n409          0            2          0.000            0.0         1.000   \n69           0            1          0.079            0.0         0.921   \n\n    compound_score sentiment  \n262         0.5859  positive  \n149         0.0000   neutral  \n494         0.5502  positive  \n409         0.0000   neutral  \n69          0.3612  positive  \n\n[5 rows x 34 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>user</th>\n      <th>created_at</th>\n      <th>full_text</th>\n      <th>clean_text</th>\n      <th>multiple_teams</th>\n      <th>no_matches</th>\n      <th>teams_concat</th>\n      <th>nhl_team_abbr</th>\n      <th>nhl_team</th>\n      <th>...</th>\n      <th>hashtag_ct</th>\n      <th>link_ct</th>\n      <th>atsign_ct</th>\n      <th>numeric_ct</th>\n      <th>uppercase_ct</th>\n      <th>positive_score</th>\n      <th>negative_score</th>\n      <th>neutral_score</th>\n      <th>compound_score</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>262</th>\n      <td>1413634069540134912</td>\n      <td>walshy66</td>\n      <td>2021-07-09 23:00:00</td>\n      <td>NEW PODCAST: Tampa win, expansion draft, and t...</td>\n      <td>new podcast tampa win expansion draft tidbits ...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>Pittsburgh Penguins,Tampa Bay Lightning</td>\n      <td>PIT</td>\n      <td>Pittsburgh Penguins</td>\n      <td>...</td>\n      <td>2</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0.226</td>\n      <td>0.0</td>\n      <td>0.774</td>\n      <td>0.5859</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>149</th>\n      <td>1411416504042655744</td>\n      <td>NathanGraviteh</td>\n      <td>2021-07-03 20:08:12</td>\n      <td>*NEW* *VIDEO*\\n\\nTODAY I Predict the ENITRE Se...</td>\n      <td>new video today predict enitre seattle kraken ...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>Montreal Canadiens,Seattle Kraken,St Louis Blues</td>\n      <td>MTL</td>\n      <td>Montreal Canadiens</td>\n      <td>...</td>\n      <td>3</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n      <td>9</td>\n      <td>0.000</td>\n      <td>0.0</td>\n      <td>1.000</td>\n      <td>0.0000</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>494</th>\n      <td>1412441045133103114</td>\n      <td>StLouisBlues</td>\n      <td>2021-07-06 15:59:21</td>\n      <td>The @NHL #ExpansionDraft is almost here! \\n\\nH...</td>\n      <td>expansiondraft almost many players seattle sel...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>Seattle Kraken,St Louis Blues</td>\n      <td>STL</td>\n      <td>St Louis Blues</td>\n      <td>...</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0.097</td>\n      <td>0.0</td>\n      <td>0.903</td>\n      <td>0.5502</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>409</th>\n      <td>1412872575970017282</td>\n      <td>nhl_tradetalk</td>\n      <td>2021-07-07 20:34:06</td>\n      <td>GM David Poile says the Nashville Predators ar...</td>\n      <td>gm david poile says nashville predators lookin...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>Nashville Predators,Seattle Kraken</td>\n      <td>SEA</td>\n      <td>Seattle Kraken</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0.000</td>\n      <td>0.0</td>\n      <td>1.000</td>\n      <td>0.0000</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>69</th>\n      <td>1411363125538983939</td>\n      <td>AntGenocide</td>\n      <td>2021-07-03 16:36:05</td>\n      <td>Am the only one ready for NHL playoffs to be o...</td>\n      <td>one ready nhl playoffs get expansion draft off...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Dallas Stars</td>\n      <td>DAL</td>\n      <td>Dallas Stars</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0.079</td>\n      <td>0.0</td>\n      <td>0.921</td>\n      <td>0.3612</td>\n      <td>positive</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 34 columns</p>\n</div>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "# classify based on VADER readme rules\n",
    "def sentiment_classifier(df, data_column):\n",
    "\n",
    "    # create a list of our conditions\n",
    "    conditions = [\n",
    "        (df[data_column] >= 0.05),\n",
    "        (df[data_column] > -0.05) & (df[data_column] < 0.05),\n",
    "        (df[data_column] <= -0.05),\n",
    "        ]\n",
    "\n",
    "    # create a list of the values we want to assign for each condition\n",
    "    values = ['positive', 'neutral', 'negative']\n",
    "    \n",
    "    # apply\n",
    "    df['sentiment'] = np.select(conditions, values)\n",
    "    return df\n",
    "\n",
    "test = sentiment_classifier(df_nhl, 'compound_score')\n",
    "\n",
    "display(test.sample(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Score: 0.363, Tweet: Sunday Morning Skate: Happy Fourth ofÂ July! https://t.co/qG9KdYsH1m\n",
      "Score: 0.363, Tweet: Sunday Morning Skate: Happy Fourth ofÂ July! https://t.co/GxkMmXdrJw\n",
      "Score: 0.36, Tweet: @FO_VVerhei I love that the NHL makes the expansion draft so that the team has a chance to be good right away. Excited for Seattle!\n",
      "Score: 0.355, Tweet: @TSN1200 NHL expansion, draft and free agency.\n",
      "Score: 0.354, Tweet: Capitals Will Lose a Good Defenseman in Expansion Draft but Gain Salary Cap Space https://t.co/dtgxq7GuIB https://t.co/TZ1PYh1LBS\n",
      "C:\\Users\\domen\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\ipykernel\\ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                      id            user          created_at  \\\n",
       "0    1413869071695814658     CBJcoverage 2021-07-10 14:33:49   \n",
       "1    1413732444151422978     NHL_Watcher 2021-07-10 05:30:55   \n",
       "2    1411070238150434818        mayorNHL 2021-07-02 21:12:15   \n",
       "3    1413974338173292550   hockeyaddicts 2021-07-10 21:32:07   \n",
       "4    1413270173352562690    ClubsCrimson 2021-07-08 22:54:01   \n",
       "..                   ...             ...                 ...   \n",
       "770  1411138243328946183          xHalfy 2021-07-03 01:42:29   \n",
       "771  1411129913785126913       CEO_Kehoe 2021-07-03 01:09:23   \n",
       "772  1411120522579095553  jacobrotenberg 2021-07-03 00:32:04   \n",
       "773  1411111522496135170  AlexLanglois15 2021-07-02 23:56:18   \n",
       "774  1411104902131105813    IllegalCurve 2021-07-02 23:30:00   \n",
       "\n",
       "                                             full_text  \\\n",
       "0    Friedman: Jack Eichel trade now expected after...   \n",
       "1    Friedman in 33 Thoughts writes a Jack Eichel t...   \n",
       "2    (new post) NHL RADIO REPLAY: Mayorâ€™s Minutes\\n...   \n",
       "3    NHL Rumors: Oilers, Blackhawks, Flyers, Sabres...   \n",
       "4    NHL Draft Order is set. Buffalo Sabres pick 1s...   \n",
       "..                                                 ...   \n",
       "770  Honestly I just want this nhl season to be ove...   \n",
       "771  @NHL_Watcher Nah. They're just sad to see thei...   \n",
       "772  Monday will be the last game of the NHL season...   \n",
       "773  @MTBO86247553 No worries here at all, the play...   \n",
       "774  It is going to be a very busy July for the thr...   \n",
       "\n",
       "                                            clean_text  multiple_teams  \\\n",
       "0    friedman jack eichel trade expected expansion ...               1   \n",
       "1    friedman thoughts writes jack eichel trade lik...               1   \n",
       "2    new post nhl radio replay mayor minutes topics...               1   \n",
       "3    nhl rumors oilers blackhawks flyers sabres hur...               1   \n",
       "4    nhl draft order set buffalo sabres pick expans...               1   \n",
       "..                                                 ...             ...   \n",
       "770  honestly want nhl season get free agency crazy...               0   \n",
       "771  nah theyre sad see dude go cant continue shit ...               0   \n",
       "772  monday last game nhl season onto expansion dra...               0   \n",
       "773  worries playoffs arent even yet lol wait till ...               0   \n",
       "774  going busy july three us illegal curve additio...               0   \n",
       "\n",
       "     no_matches                                       teams_concat  \\\n",
       "0             0  Anaheim Ducks,Boston Bruins,Calgary Flames,Los...   \n",
       "1             0  Anaheim Ducks,Boston Bruins,Calgary Flames,Los...   \n",
       "2             0     Anaheim Ducks,Los Angeles Kings,Seattle Kraken   \n",
       "3             0  Arizona Coyotes,Buffalo Sabres,Carolina Hurric...   \n",
       "4             0      Arizona Coyotes,Buffalo Sabres,Seattle Kraken   \n",
       "..          ...                                                ...   \n",
       "770           1                                                      \n",
       "771           1                                                      \n",
       "772           1                                                      \n",
       "773           1                                                      \n",
       "774           1                                                      \n",
       "\n",
       "    nhl_team_abbr         nhl_team  ... hashtag_ct link_ct atsign_ct  \\\n",
       "0             ANA    Anaheim Ducks  ...          1       1         0   \n",
       "1             ANA    Anaheim Ducks  ...          0       0         0   \n",
       "2             ANA    Anaheim Ducks  ...          0       2         0   \n",
       "3             ARZ  Arizona Coyotes  ...          0       2         0   \n",
       "4             ARZ  Arizona Coyotes  ...          0       1         1   \n",
       "..            ...              ...  ...        ...     ...       ...   \n",
       "770       Unknown          Unknown  ...          0       0         0   \n",
       "771       Unknown          Unknown  ...          0       0         1   \n",
       "772       Unknown          Unknown  ...          1       0         0   \n",
       "773       Unknown          Unknown  ...          0       0         1   \n",
       "774       Unknown          Unknown  ...          0       1         0   \n",
       "\n",
       "    numeric_ct uppercase_ct positive_score negative_score neutral_score  \\\n",
       "0            0            1          0.000          0.071         0.929   \n",
       "1            1            1          0.000          0.000         1.000   \n",
       "2            0            7          0.061          0.000         0.939   \n",
       "3            0            2          0.000          0.000         1.000   \n",
       "4            0            2          0.000          0.080         0.920   \n",
       "..         ...          ...            ...            ...           ...   \n",
       "770          0            1          0.245          0.077         0.677   \n",
       "771          0            0          0.071          0.109         0.821   \n",
       "772          0            1          0.148          0.000         0.852   \n",
       "773          0            1          0.204          0.000         0.796   \n",
       "774          0            1          0.121          0.065         0.814   \n",
       "\n",
       "    compound_score sentiment  \n",
       "0          -0.2960  negative  \n",
       "1           0.0000   neutral  \n",
       "2           0.2960  positive  \n",
       "3           0.0000   neutral  \n",
       "4          -0.5267  negative  \n",
       "..             ...       ...  \n",
       "770         0.6369  positive  \n",
       "771        -0.1471  negative  \n",
       "772         0.5106  positive  \n",
       "773         0.6288  positive  \n",
       "774         0.2732  positive  \n",
       "\n",
       "[775 rows x 34 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>user</th>\n      <th>created_at</th>\n      <th>full_text</th>\n      <th>clean_text</th>\n      <th>multiple_teams</th>\n      <th>no_matches</th>\n      <th>teams_concat</th>\n      <th>nhl_team_abbr</th>\n      <th>nhl_team</th>\n      <th>...</th>\n      <th>hashtag_ct</th>\n      <th>link_ct</th>\n      <th>atsign_ct</th>\n      <th>numeric_ct</th>\n      <th>uppercase_ct</th>\n      <th>positive_score</th>\n      <th>negative_score</th>\n      <th>neutral_score</th>\n      <th>compound_score</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1413869071695814658</td>\n      <td>CBJcoverage</td>\n      <td>2021-07-10 14:33:49</td>\n      <td>Friedman: Jack Eichel trade now expected after...</td>\n      <td>friedman jack eichel trade expected expansion ...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>Anaheim Ducks,Boston Bruins,Calgary Flames,Los...</td>\n      <td>ANA</td>\n      <td>Anaheim Ducks</td>\n      <td>...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0.000</td>\n      <td>0.071</td>\n      <td>0.929</td>\n      <td>-0.2960</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1413732444151422978</td>\n      <td>NHL_Watcher</td>\n      <td>2021-07-10 05:30:55</td>\n      <td>Friedman in 33 Thoughts writes a Jack Eichel t...</td>\n      <td>friedman thoughts writes jack eichel trade lik...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>Anaheim Ducks,Boston Bruins,Calgary Flames,Los...</td>\n      <td>ANA</td>\n      <td>Anaheim Ducks</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>1.000</td>\n      <td>0.0000</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1411070238150434818</td>\n      <td>mayorNHL</td>\n      <td>2021-07-02 21:12:15</td>\n      <td>(new post) NHL RADIO REPLAY: Mayorâ€™s Minutes\\n...</td>\n      <td>new post nhl radio replay mayor minutes topics...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>Anaheim Ducks,Los Angeles Kings,Seattle Kraken</td>\n      <td>ANA</td>\n      <td>Anaheim Ducks</td>\n      <td>...</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7</td>\n      <td>0.061</td>\n      <td>0.000</td>\n      <td>0.939</td>\n      <td>0.2960</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1413974338173292550</td>\n      <td>hockeyaddicts</td>\n      <td>2021-07-10 21:32:07</td>\n      <td>NHL Rumors: Oilers, Blackhawks, Flyers, Sabres...</td>\n      <td>nhl rumors oilers blackhawks flyers sabres hur...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>Arizona Coyotes,Buffalo Sabres,Carolina Hurric...</td>\n      <td>ARZ</td>\n      <td>Arizona Coyotes</td>\n      <td>...</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>1.000</td>\n      <td>0.0000</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1413270173352562690</td>\n      <td>ClubsCrimson</td>\n      <td>2021-07-08 22:54:01</td>\n      <td>NHL Draft Order is set. Buffalo Sabres pick 1s...</td>\n      <td>nhl draft order set buffalo sabres pick expans...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>Arizona Coyotes,Buffalo Sabres,Seattle Kraken</td>\n      <td>ARZ</td>\n      <td>Arizona Coyotes</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0.000</td>\n      <td>0.080</td>\n      <td>0.920</td>\n      <td>-0.5267</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>770</th>\n      <td>1411138243328946183</td>\n      <td>xHalfy</td>\n      <td>2021-07-03 01:42:29</td>\n      <td>Honestly I just want this nhl season to be ove...</td>\n      <td>honestly want nhl season get free agency crazy...</td>\n      <td>0</td>\n      <td>1</td>\n      <td></td>\n      <td>Unknown</td>\n      <td>Unknown</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0.245</td>\n      <td>0.077</td>\n      <td>0.677</td>\n      <td>0.6369</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>771</th>\n      <td>1411129913785126913</td>\n      <td>CEO_Kehoe</td>\n      <td>2021-07-03 01:09:23</td>\n      <td>@NHL_Watcher Nah. They're just sad to see thei...</td>\n      <td>nah theyre sad see dude go cant continue shit ...</td>\n      <td>0</td>\n      <td>1</td>\n      <td></td>\n      <td>Unknown</td>\n      <td>Unknown</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.071</td>\n      <td>0.109</td>\n      <td>0.821</td>\n      <td>-0.1471</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>772</th>\n      <td>1411120522579095553</td>\n      <td>jacobrotenberg</td>\n      <td>2021-07-03 00:32:04</td>\n      <td>Monday will be the last game of the NHL season...</td>\n      <td>monday last game nhl season onto expansion dra...</td>\n      <td>0</td>\n      <td>1</td>\n      <td></td>\n      <td>Unknown</td>\n      <td>Unknown</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0.148</td>\n      <td>0.000</td>\n      <td>0.852</td>\n      <td>0.5106</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>773</th>\n      <td>1411111522496135170</td>\n      <td>AlexLanglois15</td>\n      <td>2021-07-02 23:56:18</td>\n      <td>@MTBO86247553 No worries here at all, the play...</td>\n      <td>worries playoffs arent even yet lol wait till ...</td>\n      <td>0</td>\n      <td>1</td>\n      <td></td>\n      <td>Unknown</td>\n      <td>Unknown</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0.204</td>\n      <td>0.000</td>\n      <td>0.796</td>\n      <td>0.6288</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>774</th>\n      <td>1411104902131105813</td>\n      <td>IllegalCurve</td>\n      <td>2021-07-02 23:30:00</td>\n      <td>It is going to be a very busy July for the thr...</td>\n      <td>going busy july three us illegal curve additio...</td>\n      <td>0</td>\n      <td>1</td>\n      <td></td>\n      <td>Unknown</td>\n      <td>Unknown</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0.121</td>\n      <td>0.065</td>\n      <td>0.814</td>\n      <td>0.2732</td>\n      <td>positive</td>\n    </tr>\n  </tbody>\n</table>\n<p>775 rows Ã— 34 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "def print_top_n_reviews(df, data_column, num_rows):\n",
    "    text = 'full_text'\n",
    "    for tweet, row in df.nlargest(num_rows, data_column).iterrows():\n",
    "        print(f\"Score: {row[data_column]}, Tweet: {row[text]}\")\n",
    "    return df\n",
    "\n",
    "res = print_top_n_reviews(text_sentiment , 'positive_score', 5)\n",
    "\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\domen\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\ipykernel\\ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n  and should_run_async(code)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     positive_score                                          full_text\n",
       "0             0.000  Friedman: Jack Eichel trade now expected after...\n",
       "1             0.000  Friedman in 33 Thoughts writes a Jack Eichel t...\n",
       "2             0.061  (new post) NHL RADIO REPLAY: Mayorâ€™s Minutes\\n...\n",
       "3             0.000  NHL Rumors: Oilers, Blackhawks, Flyers, Sabres...\n",
       "4             0.000  NHL Draft Order is set. Buffalo Sabres pick 1s...\n",
       "..              ...                                                ...\n",
       "770           0.245  Honestly I just want this nhl season to be ove...\n",
       "771           0.071  @NHL_Watcher Nah. They're just sad to see thei...\n",
       "772           0.148  Monday will be the last game of the NHL season...\n",
       "773           0.204  @MTBO86247553 No worries here at all, the play...\n",
       "774           0.121  It is going to be a very busy July for the thr...\n",
       "\n",
       "[775 rows x 2 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>positive_score</th>\n      <th>full_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.000</td>\n      <td>Friedman: Jack Eichel trade now expected after...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.000</td>\n      <td>Friedman in 33 Thoughts writes a Jack Eichel t...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.061</td>\n      <td>(new post) NHL RADIO REPLAY: Mayorâ€™s Minutes\\n...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.000</td>\n      <td>NHL Rumors: Oilers, Blackhawks, Flyers, Sabres...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.000</td>\n      <td>NHL Draft Order is set. Buffalo Sabres pick 1s...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>770</th>\n      <td>0.245</td>\n      <td>Honestly I just want this nhl season to be ove...</td>\n    </tr>\n    <tr>\n      <th>771</th>\n      <td>0.071</td>\n      <td>@NHL_Watcher Nah. They're just sad to see thei...</td>\n    </tr>\n    <tr>\n      <th>772</th>\n      <td>0.148</td>\n      <td>Monday will be the last game of the NHL season...</td>\n    </tr>\n    <tr>\n      <th>773</th>\n      <td>0.204</td>\n      <td>@MTBO86247553 No worries here at all, the play...</td>\n    </tr>\n    <tr>\n      <th>774</th>\n      <td>0.121</td>\n      <td>It is going to be a very busy July for the thr...</td>\n    </tr>\n  </tbody>\n</table>\n<p>775 rows Ã— 2 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "top_tweet_list = []\n",
    "\n",
    "def print_top_n_reviews(df, data_column, num_rows):\n",
    "    text = 'full_text'\n",
    "    top = df.nlargest(num_rows, data_column)\n",
    "    top_tweets = df[[data_column,text]]\n",
    "    return top_tweets\n",
    "\n",
    "res = print_top_n_reviews(text_sentiment , 'positive_score', 5)\n",
    "\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\domen\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\ipykernel\\ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n  and should_run_async(code)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   positive_score                                          full_text\n",
       "1           0.363  Sunday Morning Skate: Happy Fourth ofÂ July! ht...\n",
       "2           0.363  Sunday Morning Skate: Happy Fourth ofÂ July! ht...\n",
       "3           0.360  @FO_VVerhei I love that the NHL makes the expa...\n",
       "4           0.355     @TSN1200 NHL expansion, draft and free agency.\n",
       "5           0.354  Capitals Will Lose a Good Defenseman in Expans..."
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>positive_score</th>\n      <th>full_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>0.363</td>\n      <td>Sunday Morning Skate: Happy Fourth ofÂ July! ht...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.363</td>\n      <td>Sunday Morning Skate: Happy Fourth ofÂ July! ht...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.360</td>\n      <td>@FO_VVerhei I love that the NHL makes the expa...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.355</td>\n      <td>@TSN1200 NHL expansion, draft and free agency.</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.354</td>\n      <td>Capitals Will Lose a Good Defenseman in Expans...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "num_rows = 5\n",
    "data_column = 'positive_score'\n",
    "text = 'full_text'\n",
    "df = text_sentiment\n",
    "top = df.nlargest(num_rows, data_column)\n",
    "top_tweets = top[[data_column,text]].reset_index()\n",
    "top_tweets = top_tweets.drop(columns = 'index')\n",
    "top_tweets.index = top_tweets.index + 1 \n",
    "top_tweets.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\domen\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\ipykernel\\ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "sent_type = 'Positive'\n",
    "   \n",
    "if sent_type == 'Positive':\n",
    "    sent_nm= 'positive_score'\n",
    "\n",
    "# Scenario 2: Bigrams\n",
    "if sent_type== 'Neutral':\n",
    "    sent_nm == 'neutral_score'\n",
    "\n",
    "# Scenario 3: Trigrams\n",
    "if sent_type == 'Negative':\n",
    "    sent_nm == 'negative_score'\n",
    "    \n",
    "text = 'full_text'\n",
    "top = df.nlargest(num_rows, sent_nm)\n",
    "top_tweets = top[[sent_nm,text]]"
   ]
  },
  {
   "source": [
    "## Part 6: Data & Text Cleaning\n",
    "* Change to lower case\n",
    "* Remove punctuation, stopwords, URLs, html tags, emojis, emoticons\n",
    "* Spell correction\n",
    "* Explore & remove custom stopwords"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy to preserve the raw data\n",
    "df_tweets = df_tweets_raw.copy()\n",
    "\n",
    "# Sample the tweets\n",
    "df_tweets_raw.full_text[26]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View more sample tweets\n",
    "for i in range(0,5):\n",
    "    print(str(i+1) + ') ' + df_tweets_raw.full_text[i] + '\\n')"
   ]
  },
  {
   "source": [
    "## Step 6a: Convert tweets to lower case"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert transcripts to lower case\n",
    "df_tweets['text_cleaned'] = df_tweets['full_text'].map(lambda x: x.lower())\n",
    "\n",
    "# Print out sample of cleaned transcripts\n",
    "print(\"Cleaned tweet:\\n\" + df_tweets['text_cleaned'][26])"
   ]
  },
  {
   "source": [
    "## Step 6b: Remove URLs, html tags, punctuation, stopwords, emojis, emoticons"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove tweet URLs\n",
    "df_tweets['text_cleaned'] = df_tweets.text_cleaned.map(lambda x: re.sub(r'https\\:\\/\\/t\\.co\\/*\\w*', '', x, flags=re.MULTILINE).strip())\n",
    "\n",
    "# Print out sample of cleaned transcripts\n",
    "print(\"Cleaned tweet:\\n\" + df_tweets['text_cleaned'][26])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove punctuation\n",
    "df_tweets['text_cleaned'] = df_tweets.text_cleaned.str.replace('[^\\w\\s]','')\n",
    "\n",
    "# Print out sample of cleaned transcripts\n",
    "print(\"Cleaned tweet:\\n\" + df_tweets['text_cleaned'][26])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove stopwords (start with library to identify stopwords)\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Define english & french stopwords \n",
    "stop_en = stopwords.words('english')\n",
    "stop_fr = stopwords.words('french')\n",
    "\n",
    "# Remove english & french stopwords\n",
    "df_tweets['text_cleaned'] = df_tweets.text_cleaned.apply(lambda x: \" \".join(x for x in x.split() if x not in stop_en))\n",
    "df_tweets['text_cleaned'] = df_tweets.text_cleaned.apply(lambda x: \" \".join(x for x in x.split() if x not in stop_fr))\n",
    "\n",
    "# Print out sample of cleaned transcripts\n",
    "print(\"Cleaned tweet:\\n\" + df_tweets['text_cleaned'][26])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to remove emojis --> e.g. ðŸ˜œ\n",
    "def remove_emoji(text):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                               u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U000024C2-\\U0001F251\"\n",
    "                               u\"\\U0001f926-\\U0001f937\"\n",
    "                               u\"\\U00010000-\\U0010ffff\"\n",
    "                               u\"\\u2640-\\u2642\"\n",
    "                               u\"\\u2600-\\u2B55\"\n",
    "                               u\"\\u200d\"\n",
    "                               u\"\\u23cf\"\n",
    "                               u\"\\u23e9\"\n",
    "                               u\"\\u231a\"\n",
    "                               u\"\\ufe0f\"  # dingbats\n",
    "                               u\"\\u3030\"\n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', text)\n",
    "\n",
    "# Remove all emojis\n",
    "df_tweets['text_cleaned'] = df_tweets.text_cleaned.apply(lambda x: remove_emoji(x))\n",
    "\n",
    "# Print out sample of cleaned transcripts\n",
    "print(\"Cleaned tweet:\\n\" + df_tweets['text_cleaned'][26])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to remove emoticons --> e.g. :-)\n",
    "\n",
    "# Libraries\n",
    "!pip install emot\n",
    "from emot.emo_unicode import UNICODE_EMO, EMOTICONS\n",
    "\n",
    "# Function for removing emoticons\n",
    "def remove_emoticons(text):\n",
    "    emoticon_pattern = re.compile(u'(' + u'|'.join(k for k in EMOTICONS) + u')')\n",
    "    return emoticon_pattern.sub(r'', text)\n",
    "\n",
    "# Remove all emoticons\n",
    "df_tweets['text_cleaned'] = df_tweets.text_cleaned.apply(lambda x: remove_emoticons(x))\n",
    "\n",
    "# Print out sample of cleaned transcripts\n",
    "print(\"Cleaned tweet:\\n\" + df_tweets['text_cleaned'][26])"
   ]
  },
  {
   "source": [
    "## Step 6c: Tokenize and lemmatize tweets\n",
    "Tokenization parses tweets into individual words and lemmatization removes inflectional endings (ie. endings that add grammatical meaning). These methods prepare the data for word frequency and n-gram analysis.\n",
    "\n",
    "Methods used below reference this post: https://towardsdatascience.com/from-dataframe-to-n-grams-e34e29df3460"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text_round1(text):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                               u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U000024C2-\\U0001F251\"\n",
    "                               u\"\\U0001f926-\\U0001f937\"\n",
    "                               u\"\\U00010000-\\U0010ffff\"\n",
    "                               u\"\\u2640-\\u2642\"\n",
    "                               u\"\\u2600-\\u2B55\"\n",
    "                               u\"\\u200d\"\n",
    "                               u\"\\u23cf\"\n",
    "                               u\"\\u23e9\"\n",
    "                               u\"\\u231a\"\n",
    "                               u\"\\ufe0f\"  # dingbats\n",
    "                               u\"\\u3030\"\n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "    text = emoji_pattern.sub(r'', text) # remove emoji\n",
    "    '''Make text lowercase, remove text in square brackets, remove punctuation and remove words containing numbers.'''\n",
    "    text = ' ' + text # added space because there was some weirdness for first word (strip later)\n",
    "    text = text.lower() # convert all text to lowercase\n",
    "    text = re.sub(r'(\\s)@\\w+', '', text) # remove whole word if starts with @\n",
    "    text = re.sub(r'(\\s)\\w*\\d\\w*\\w+', '', text) # remove whole word if starts with number\n",
    "    text = re.sub(r'https\\:\\/\\/t\\.co\\/*\\w*', '', text) # remove https links\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text) # removes punctuation\n",
    "    text = re.sub('\\[.*?\\]', '', text) # removes text in square brackets\n",
    "    #text = re.sub('\\w*\\d\\w*', '', text) # remove whole word if starts with number\n",
    "    #text = re.sub(r'(\\s)#\\w+', '', text) # remove whole word if starts with #\n",
    "    text = text.strip()\n",
    "    return text\n",
    "\n",
    "round1 = lambda x: clean_text_round1(x)\n",
    "\n",
    "df_tweets_raw['clean_text'] = df_tweets_raw.full_text.apply(round1)\n",
    "print(\"Cleaned tweet:\\n\" + df_tweets_raw['clean_text'][4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def round3_text_clean(text):\n",
    "    #TODO: add emoticons and emojis to this!\n",
    "    # Load in stopwords\n",
    "    stopwords_en = nltk.corpus.stopwords.words('english')\n",
    "    stopwords_fr = nltk.corpus.stopwords.words('french')\n",
    "    stopwords = stopwords_en + stopwords_fr\n",
    "    # Create pre-clean character count feature\n",
    "    text = text.apply(lambda x: \" \".join(x for x in x.split() if x not in stopwords))\n",
    "    return text\n",
    "\n",
    "df3 = round3_text_clean(df_tweets_raw.full_text)\n",
    "\n",
    "df3.head(4)"
   ]
  },
  {
   "source": [
    "## Step 6d: Word correction (needs work & review!)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO Check to see if this worked as intended...\n",
    "\n",
    "# Spell correction \n",
    "from textblob import TextBlob\n",
    "df_tweets['text_cleaned'] = df_tweets.text_cleaned.[:5].apply(lambda x: str(TextBlob(x).correct()))"
   ]
  },
  {
   "source": [
    "# Step 7: Text analytics (analyze tweets)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Step 7a: Word frequencies and n-grams"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "import nltk\n",
    "import unicodedata\n",
    "\n",
    "\n",
    "def text_clean_round2(text):\n",
    "    \"\"\"\n",
    "    A simple function to clean up the data. All the words that\n",
    "    are not designated as a stop word is then lemmatized after\n",
    "    encoding and basic regex parsing are performed.\n",
    "    \"\"\"\n",
    "    wnl = nltk.stem.WordNetLemmatizer()\n",
    "    stopwords = nltk.corpus.stopwords.words('english')\n",
    "    text = (unicodedata.normalize('NFKD', text)\n",
    "    .encode('ascii', 'ignore')\n",
    "    .decode('utf-8', 'ignore'))\n",
    "    words = re.sub(r'[^\\w\\s]', '', text).split()\n",
    "    return [wnl.lemmatize(word) for word in words if word not in stopwords]\n",
    "\n",
    "\n",
    "# Word cloud\n",
    "txt = text_clean_round2(''.join(str(df_tweets.text_cleaned.tolist())))\n",
    "\n",
    "\n",
    "# Python program to convert a list\n",
    "# to string using join() function\n",
    "    \n",
    "# Function to convert  \n",
    "def listToString(s): \n",
    "    \n",
    "    # initialize an empty string\n",
    "    str1 = \" \" \n",
    "    \n",
    "    # return string  \n",
    "    return (str1.join(s))\n",
    "        \n",
    "        \n",
    "# Driver code    \n",
    "print(listToString(txt)) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweets_ngrams(n, top_n, df):\n",
    "    text = df.text_cleaned\n",
    "    words = text_clean_round2(''.join(str(text.tolist())))\n",
    "    result = (pd.Series(data = nltk.ngrams(words, n), name = 'freq').value_counts())[:top_n]\n",
    "    return result.to_frame()\n",
    "\n",
    "word_series = tweets_ngrams(1, 2, df_tweets)\n",
    "bigram_series = tweets_ngrams(2, 2, df_tweets)\n",
    "trigram_series = tweets_ngrams(3, 2, df_tweets)\n",
    "\n",
    "word_series['ngram'] = 'unigram'\n",
    "bigram_series['ngram'] = 'bigram'\n",
    "trigram_series['ngram'] = 'trigram'\n",
    "\n",
    "rez = word_series.append([bigram_series, trigram_series])\n",
    "rez['ngram_nm'] = rez.index\n",
    "\n",
    "\n",
    "rez.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_ngrams(top_n, df):\n",
    "    text = df.text_cleaned\n",
    "    words = text_clean_round2(''.join(str(text.tolist())))\n",
    "    unigram = ((pd.Series(data = nltk.ngrams(words, 1), name = 'freq').value_counts())[:top_n]).to_frame()\n",
    "    unigram['ngram'] = 'unigram'\n",
    "    bigram = ((pd.Series(data = nltk.ngrams(words, 2), name = 'freq').value_counts())[:top_n]).to_frame()\n",
    "    bigram['ngram'] = 'bigram'\n",
    "    trigram = ((pd.Series(data = nltk.ngrams(words, 3), name = 'freq').value_counts())[:top_n]).to_frame()\n",
    "    trigram['ngram'] = 'trigram'\n",
    "    result = unigram.append([bigram, trigram])\n",
    "    result['ngram_nm'] = result.index\n",
    "    return result\n",
    "\n",
    "rezz = all_ngrams(3, df_tweets)\n",
    "\n",
    "\n",
    "rez.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('whitegrid')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function\n",
    "def plot_30_most_common_words(count_data, count_vectorizer):\n",
    "    words = count_vectorizer.get_feature_names()\n",
    "    total_counts = np.zeros(len(words))\n",
    "    for t in count_data:\n",
    "        total_counts+=t.toarray()[0]\n",
    "    \n",
    "    count_dict = (zip(words, total_counts))\n",
    "    count_dict = sorted(count_dict, key=lambda x:x[1], reverse=True)[0:20]\n",
    "    words = [w[0] for w in count_dict]\n",
    "    counts = [w[1] for w in count_dict]\n",
    "    x_pos = np.arange(len(words)) \n",
    "    \n",
    "    plt.figure(2, figsize=(15, 15/1.6180))\n",
    "    plt.subplot(title='30 most common words')\n",
    "    sns.set_context(\"notebook\", font_scale=1.25, rc={\"lines.linewidth\": 2.5})\n",
    "    sns.barplot(x_pos, counts, palette='husl', orient = 'h')\n",
    "    plt.yticks(x_pos, words) \n",
    "    plt.ylabel('words')\n",
    "    plt.xlabel('counts')\n",
    "    plt.show()\n",
    "\n",
    "# Initialise the count vectorizer with the English stop words\n",
    "count_vectorizer = CountVectorizer(stop_words='english')\n",
    "\n",
    "# Fit and transform the processed transcripts\n",
    "count_data = count_vectorizer.fit_transform(df_tweets['text_cleaned'])\n",
    "\n",
    "# Visualise the 30 most common words\n",
    "plot_30_most_common_words(count_data, count_vectorizer)"
   ]
  },
  {
   "source": [
    "## Step 7b: Sentiment analysis"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\domen\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\ipykernel\\ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "# Function 8\n",
    "#----------------\n",
    "\n",
    "# Credit: https://jackmckew.dev/sentiment-analysis-text-cleaning-in-python-with-vader.html\n",
    "sid_analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Get sentiment\n",
    "def get_sentiment(text:str, analyser, desired_type:str='pos'):\n",
    "    # Get sentiment from text\n",
    "    sentiment_score = analyser.polarity_scores(text)\n",
    "    return sentiment_score[desired_type]\n",
    "\n",
    "# Get Sentiment scores\n",
    "def get_sentiment_scores(df, data_column):\n",
    "    df[f'positive_score'] = df[data_column].astype(str).apply(lambda x: get_sentiment(x,sid_analyzer,'pos'))\n",
    "    df[f'negative_score'] = df[data_column].astype(str).apply(lambda x: get_sentiment(x,sid_analyzer,'neg'))\n",
    "    df[f'neutral_score'] = df[data_column].astype(str).apply(lambda x: get_sentiment(x,sid_analyzer,'neu'))\n",
    "    df[f'compound_score'] = df[data_column].astype(str).apply(lambda x: get_sentiment(x,sid_analyzer,'compound'))\n",
    "    return df\n",
    "\n",
    "# Function 9\n",
    "#----------------\n",
    "# Credit: https://www.dataquest.io/blog/tutorial-add-column-pandas-dataframe-based-on-if-else-condition/\n",
    "\n",
    "# classify based on VADER readme rules\n",
    "def sentiment_classifier(df, data_column):\n",
    "\n",
    "    # create a list of our conditions\n",
    "    conditions = [\n",
    "        (df[data_column] >= 0.05),\n",
    "        (df[data_column] > -0.05) & (df[data_column] < 0.05),\n",
    "        (df[data_column] <= -0.05),\n",
    "        ]\n",
    "\n",
    "    # create a list of the values we want to assign for each condition\n",
    "    values = ['Positive', 'Neutral', 'Negative']\n",
    "    \n",
    "    # apply\n",
    "    df['sentiment'] = np.select(condlist = conditions, choicelist = values)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\domen\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\ipykernel\\ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n  and should_run_async(code)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   expansion_type  tweets  avg_compound_score  median_compound_score  \\\n",
       "0          Kraken     214            0.210047                0.00000   \n",
       "1  Rest of League     306            0.177417                0.00000   \n",
       "2         Unknown     186            0.209221                0.08995   \n",
       "\n",
       "   min_compound_score  max_compound_score  \n",
       "0             -0.7339              0.9704  \n",
       "1             -0.8074              0.9260  \n",
       "2             -0.8555              0.9481  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>expansion_type</th>\n      <th>tweets</th>\n      <th>avg_compound_score</th>\n      <th>median_compound_score</th>\n      <th>min_compound_score</th>\n      <th>max_compound_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Kraken</td>\n      <td>214</td>\n      <td>0.210047</td>\n      <td>0.00000</td>\n      <td>-0.7339</td>\n      <td>0.9704</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Rest of League</td>\n      <td>306</td>\n      <td>0.177417</td>\n      <td>0.00000</td>\n      <td>-0.8074</td>\n      <td>0.9260</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Unknown</td>\n      <td>186</td>\n      <td>0.209221</td>\n      <td>0.08995</td>\n      <td>-0.8555</td>\n      <td>0.9481</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 97
    }
   ],
   "source": [
    "# Get sentiment scores on raw tweets\n",
    "text_sentiment = get_sentiment_scores(df_nhl, 'full_text')\n",
    "\n",
    "# Add sentiment classification\n",
    "text_sentiment = sentiment_classifier(df_nhl, 'compound_score')\n",
    "\n",
    "# Select columns to output\n",
    "df_sentiment = text_sentiment[['id', 'created_at', 'nhl_team_abbr', 'nhl_team', 'expansion_type', 'full_text', 'sentiment', 'positive_score', 'negative_score', 'neutral_score', 'compound_score']]\n",
    "\n",
    "# Sentiment group dataframe\n",
    "sentiment_group = df_sentiment.groupby(['sentiment']).agg({'id': 'nunique'}).reset_index()\n",
    "expansion_group = df_sentiment.groupby(['expansion_type', 'sentiment']).agg({'id': 'nunique', 'compound_score': ['mean', 'median', 'min', 'max']}).reset_index(level=[0,1])\n",
    "team_group = df_sentiment.groupby(['nhl_team_abbr', 'nhl_team']).agg({'id': 'nunique', 'compound_score': ['mean', 'median', 'min', 'max']}).reset_index(level=[0,1])\n",
    "team_group.columns = ['nhl_team_abbr', 'nhl_team', 'tweets', 'avg_compound_score', 'median_compound_score', 'min_compound_score', 'max_compound_score']\n",
    "expansion_group.columns = ['expansion_type', 'sentiment', 'tweets', 'avg_compound_score', 'median_compound_score', 'min_compound_score', 'max_compound_score']\n",
    "\n",
    "expansion_group2 = df_sentiment.groupby(['expansion_type']).agg({'id': 'nunique', 'compound_score': ['mean', 'median', 'min', 'max']}).reset_index(level=[0,0])\n",
    "expansion_group2.columns = ['expansion_type',  'tweets', 'avg_compound_score', 'median_compound_score', 'min_compound_score', 'max_compound_score']\n",
    "\n",
    "#unknown_group = unknown_group.loc[unknown_group['nhl_team_abbr'] == 'Unknown']\n",
    "\n",
    "\n",
    "# rename\n",
    "sentiment_group.rename(columns={\"id\": \"tweets\"}, inplace = True)\n",
    "expansion_group.rename(columns={\"id\": \"tweets\"}, inplace = True)\n",
    "team_group.rename(columns={\"id\": \"tweets\"}, inplace = True)\n",
    "\n",
    "\n",
    "#team_group.index.to_flat_index()\n",
    "expansion_group2.head(10)\n",
    "#team_group.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}